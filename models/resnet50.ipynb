{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPshPGoiJY6Rv6Ac2mMCjGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyomee2/scooter-parking-detector/blob/main/models/resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKqGk6QIxiDv"
      },
      "source": [
        "## 구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGz6wFzHaMmM",
        "outputId": "7cc6a2f5-f1bb-4758-ab67-0098618c1ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. tensorflow 설치"
      ],
      "metadata": {
        "id": "Fm6VQ9e3WWIp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMZ5pTbwcGr_",
        "outputId": "6aa4bddc-2a5b-46b4-ea52-cf16839f4049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cnn 학습을 위한 디렉토리 구조 생성. (현재는 mobilenet 학습 시 디렉토리 구조를 생성했으므로 실행x)"
      ],
      "metadata": {
        "id": "PSPkXr4ZmfOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from math import floor\n",
        "\n",
        "# 수정된 경로: 모두 Google Drive 내에서 작업\n",
        "original_base = '/content/gdrive/MyDrive/scooter-parking-detector/dataset/cnn'\n",
        "combined_temp = '/content/gdrive/MyDrive/scooter-parking-detector/dataset/cnn_2stages/_temp_combined'\n",
        "new_base = '/content/gdrive/MyDrive/scooter-parking-detector/dataset/cnn_2stages'\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "class_names = ['improper', 'proper', 'noise']\n",
        "random.seed(42)\n",
        "\n",
        "# cnn 데이터셋 통합 후 재분할 준비\n",
        "# combined_temp 폴더 초기화 및 생성\n",
        "if os.path.exists(combined_temp):\n",
        "    shutil.rmtree(combined_temp)\n",
        "os.makedirs(combined_temp, exist_ok=True)\n",
        "\n",
        "for cls in class_names:\n",
        "    os.makedirs(os.path.join(combined_temp, cls), exist_ok=True)\n",
        "    for split in splits:\n",
        "        src = os.path.join(original_base, split, cls)\n",
        "        if os.path.exists(src):\n",
        "            for f in os.listdir(src):\n",
        "                src_path = os.path.join(src, f)\n",
        "                if os.path.isfile(src_path):\n",
        "                    # 원본 split 정보를 파일명에 붙여서 저장 (ex: train_abc.jpg)\n",
        "                    shutil.copy(src_path, os.path.join(combined_temp, cls, f\"{split}_{f}\"))\n",
        "\n",
        "print(\"✅ CNN 데이터셋 통합 완료!\")\n",
        "\n",
        "# 재분할 및 stage별 폴더 생성 함수\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def split_and_copy(src_dir, dst_map, ratios):\n",
        "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
        "    random.shuffle(files)\n",
        "    total = len(files)\n",
        "    train_end = floor(ratios[0] * total)\n",
        "    val_end = train_end + floor(ratios[1] * total)\n",
        "\n",
        "    for i, phase in enumerate(['train', 'val', 'test']):\n",
        "        phase_files = files[:train_end] if phase == 'train' else \\\n",
        "                      files[train_end:val_end] if phase == 'val' else \\\n",
        "                      files[val_end:]\n",
        "        dst_dir = dst_map[phase]\n",
        "        ensure_dir(dst_dir)\n",
        "        for fname in phase_files:\n",
        "            shutil.copy(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
        "\n",
        "# stage1 / stage2 클래스 매핑\n",
        "stage1_map = {\n",
        "    'noise': '0_no_kickboard',\n",
        "    'improper': '1_has_kickboard',\n",
        "    'proper': '1_has_kickboard'\n",
        "}\n",
        "\n",
        "stage2_map = {\n",
        "    'improper': '0_improper',\n",
        "    'proper': '2_proper'\n",
        "}\n",
        "\n",
        "# stage별 분할 및 저장\n",
        "for cls in class_names:\n",
        "    src_dir = os.path.join(combined_temp, cls)\n",
        "\n",
        "    # Stage 1 (noise 포함)\n",
        "    dst_stage1 = {\n",
        "        'train': os.path.join(new_base, 'stage1', 'train', stage1_map[cls]),\n",
        "        'val': os.path.join(new_base, 'stage1', 'val', stage1_map[cls]),\n",
        "        'test': os.path.join(new_base, 'stage1', 'test', stage1_map[cls])\n",
        "    }\n",
        "    split_and_copy(src_dir, dst_stage1, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "    # Stage 2 (noise 제외)\n",
        "    if cls != 'noise':\n",
        "        dst_stage2 = {\n",
        "            'train': os.path.join(new_base, 'stage2', 'train', stage2_map[cls]),\n",
        "            'val': os.path.join(new_base, 'stage2', 'val', stage2_map[cls]),\n",
        "            'test': os.path.join(new_base, 'stage2', 'test', stage2_map[cls])\n",
        "        }\n",
        "        split_and_copy(src_dir, dst_stage2, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "print(\"✅ stage1, stage2 데이터셋 분할 및 생성 완료!\")"
      ],
      "metadata": {
        "id": "oM4fES1-SKD1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "164ef5ff-20ec-4714-f649-ff6e94da802e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fa628447490e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;31m# 원본 split 정보를 파일명에 붙여서 저장 (ex: train_abc.jpg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{split}_{f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ CNN 데이터셋 통합 완료!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    267\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0m_USE_CP_SENDFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                             \u001b[0m_fastcopy_sendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0m_GiveupOnFastCopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36m_fastcopy_sendfile\u001b[0;34m(fsrc, fdst)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;31m# ...in oder to have a more informative exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 이상 이미지 제거"
      ],
      "metadata": {
        "id": "XnjY_hTbhtSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_dataset(directory):\n",
        "    valid_exts = ['.jpg', '.jpeg', '.png']\n",
        "    removed_files = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext not in valid_exts:\n",
        "                file_path = os.path.join(root, fname)\n",
        "                removed_files.append(file_path)\n",
        "                os.remove(file_path)\n",
        "\n",
        "    return removed_files\n",
        "\n",
        "# 데이터셋 경로 정리\n",
        "removed = clean_dataset('/content/gdrive/MyDrive/scooter-parking-detector/dataset/cnn_2stages')\n",
        "print(f\"✅ 삭제된 비이미지 파일 개수: {len(removed)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b3923d-be82-4da6-d471-994f00b90da8",
        "id": "gD04r0o2Sa7S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 삭제된 비이미지 파일 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def clean_corrupted_images(directory):\n",
        "    corrupted = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext in ['.jpg', '.jpeg', '.png']:\n",
        "                fpath = os.path.join(root, fname)\n",
        "                try:\n",
        "                    img = Image.open(fpath)\n",
        "                    img.verify()  # 파일이 진짜 이미지인지 검사\n",
        "                except Exception:\n",
        "                    corrupted.append(fpath)\n",
        "                    os.remove(fpath)\n",
        "    return corrupted\n",
        "\n",
        "# 실제 이미지 열어서 검사\n",
        "bad_files = clean_corrupted_images('/content/gdrive/MyDrive/scooter-parking-detector/dataset/cnn_2stages')\n",
        "print(f\"🧹 삭제된 손상된 이미지 파일 개수: {len(bad_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQBdAjRd32Oj",
        "outputId": "8bb2b01b-1117-4aa5-8889-4cf9bb4b69f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 삭제된 손상된 이미지 파일 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 학습"
      ],
      "metadata": {
        "id": "V4YndADJm_Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import os\n",
        "\n",
        "# ✅ 경로 설정\n",
        "base_path = '/content/gdrive/MyDrive/scooter-parking-detector/dataset/cnn_2stages'\n",
        "stage1_train = os.path.join(base_path, 'stage1', 'train')\n",
        "stage1_val = os.path.join(base_path, 'stage1', 'val')\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# ✅ 데이터 증강 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ Stage 1: 킥보드 유무 이진 분류\n",
        "train_gen_1 = datagen.flow_from_directory(stage1_train, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "val_gen_1 = val_datagen.flow_from_directory(stage1_val, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "\n",
        "base_model_1 = ResNet50(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x1 = GlobalAveragePooling2D()(base_model_1.output)\n",
        "out1 = Dense(1, activation='sigmoid')(x1)\n",
        "model_1 = Model(inputs=base_model_1.input, outputs=out1)\n",
        "\n",
        "for layer in base_model_1.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_1.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
        "\n",
        "callbacks_1 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint('/content/gdrive/MyDrive/scooter-parking-detector/models/result/resnet/best_stage1_resnet50.h5',\n",
        "                    monitor='val_auc', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "print(\"\\n🔹 Stage 1 (ResNet50) 학습 시작\")\n",
        "history_1 = model_1.fit(train_gen_1, validation_data=val_gen_1, epochs=50, callbacks=callbacks_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-OY9z8FmObe",
        "outputId": "2092eed6-6996-4c06-8799-c254a09a187f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 871 images belonging to 2 classes.\n",
            "Found 108 images belonging to 2 classes.\n",
            "\n",
            "🔹 Stage 1 (ResNet50) 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - auc: 0.5955 - loss: 0.5646"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1s/step - auc: 0.5990 - loss: 0.5592 - val_auc: 0.5290 - val_loss: 1.1270 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639ms/step - auc: 0.8062 - loss: 0.3080"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 800ms/step - auc: 0.8077 - loss: 0.3070 - val_auc: 0.6029 - val_loss: 0.9705 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 817ms/step - auc: 0.9029 - loss: 0.2481 - val_auc: 0.5964 - val_loss: 0.8180 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646ms/step - auc: 0.9080 - loss: 0.2230"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 832ms/step - auc: 0.9076 - loss: 0.2233 - val_auc: 0.6412 - val_loss: 0.7259 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784ms/step - auc: 0.9165 - loss: 0.2107"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 871ms/step - auc: 0.9165 - loss: 0.2109 - val_auc: 0.8154 - val_loss: 0.5857 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800ms/step - auc: 0.8687 - loss: 0.2259"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 887ms/step - auc: 0.8700 - loss: 0.2256 - val_auc: 0.8778 - val_loss: 0.4446 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790ms/step - auc: 0.9503 - loss: 0.1975"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 876ms/step - auc: 0.9501 - loss: 0.1973 - val_auc: 0.9176 - val_loss: 0.3288 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777ms/step - auc: 0.9328 - loss: 0.1917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 865ms/step - auc: 0.9331 - loss: 0.1915 - val_auc: 0.9237 - val_loss: 0.2950 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791ms/step - auc: 0.9478 - loss: 0.1761"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 957ms/step - auc: 0.9474 - loss: 0.1766 - val_auc: 0.9240 - val_loss: 0.2704 - learning_rate: 1.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806ms/step - auc: 0.9576 - loss: 0.1561"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 894ms/step - auc: 0.9570 - loss: 0.1568 - val_auc: 0.9427 - val_loss: 0.2539 - learning_rate: 1.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 818ms/step - auc: 0.9406 - loss: 0.1714 - val_auc: 0.9380 - val_loss: 0.2301 - learning_rate: 1.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753ms/step - auc: 0.9373 - loss: 0.1760"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 913ms/step - auc: 0.9372 - loss: 0.1763 - val_auc: 0.9534 - val_loss: 0.2256 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - auc: 0.9692 - loss: 0.1539"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 859ms/step - auc: 0.9686 - loss: 0.1544 - val_auc: 0.9599 - val_loss: 0.2397 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 847ms/step - auc: 0.9566 - loss: 0.1564 - val_auc: 0.9484 - val_loss: 0.2224 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 746ms/step - auc: 0.9644 - loss: 0.1529 - val_auc: 0.9502 - val_loss: 0.2221 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - auc: 0.9377 - loss: 0.1344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 816ms/step - auc: 0.9387 - loss: 0.1351 - val_auc: 0.9631 - val_loss: 0.1908 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 828ms/step - auc: 0.9286 - loss: 0.1815 - val_auc: 0.9613 - val_loss: 0.2195 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651ms/step - auc: 0.9772 - loss: 0.1263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 803ms/step - auc: 0.9769 - loss: 0.1272 - val_auc: 0.9649 - val_loss: 0.1983 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 840ms/step - auc: 0.9674 - loss: 0.1392 - val_auc: 0.9466 - val_loss: 0.2193 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - auc: 0.9731 - loss: 0.1223"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 790ms/step - auc: 0.9732 - loss: 0.1225 - val_auc: 0.9767 - val_loss: 0.1671 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 801ms/step - auc: 0.9739 - loss: 0.1307 - val_auc: 0.9645 - val_loss: 0.1802 - learning_rate: 1.0000e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 695ms/step - auc: 0.9782 - loss: 0.1115 - val_auc: 0.9276 - val_loss: 0.2174 - learning_rate: 1.0000e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 697ms/step - auc: 0.9673 - loss: 0.1455 - val_auc: 0.9448 - val_loss: 0.2386 - learning_rate: 1.0000e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 723ms/step - auc: 0.9760 - loss: 0.1419 - val_auc: 0.9606 - val_loss: 0.1807 - learning_rate: 5.0000e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 697ms/step - auc: 0.9883 - loss: 0.1013 - val_auc: 0.9509 - val_loss: 0.1813 - learning_rate: 5.0000e-06\n",
            "Found 751 images belonging to 2 classes.\n",
            "Found 93 images belonging to 2 classes.\n",
            "\n",
            "🔹 Stage 2 (ResNet50) 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747ms/step - auc: 0.4025 - loss: 1.7367"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - auc: 0.4050 - loss: 1.7283 - val_auc: 0.6527 - val_loss: 0.6489 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 637ms/step - auc: 0.6283 - loss: 1.2724 - val_auc: 0.6400 - val_loss: 0.6697 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 633ms/step - auc: 0.7390 - loss: 1.0118 - val_auc: 0.5701 - val_loss: 0.6869 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 655ms/step - auc: 0.7676 - loss: 0.9837 - val_auc: 0.4429 - val_loss: 0.7194 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 634ms/step - auc: 0.7984 - loss: 0.9054 - val_auc: 0.4289 - val_loss: 0.7410 - learning_rate: 5.0000e-06\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 637ms/step - auc: 0.8269 - loss: 0.8794 - val_auc: 0.4851 - val_loss: 0.7119 - learning_rate: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ✅ Stage 2: 적절 vs 부적절\n",
        "train_gen_2 = datagen.flow_from_directory(\n",
        "    stage2_train,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "val_gen_2 = val_datagen.flow_from_directory(\n",
        "    stage2_val,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 클래스 가중치 설정\n",
        "class_weight_2 = {\n",
        "    0: 10.0,\n",
        "    1: 1.0\n",
        "}  # improper : proper\n",
        "\n",
        "# ✅ Stage 2 모델 구성\n",
        "base_model_2 = ResNet50(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x2 = GlobalAveragePooling2D()(base_model_2.output)\n",
        "out2 = Dense(2, activation='softmax')(x2)\n",
        "model_2 = Model(inputs=base_model_2.input, outputs=out2)\n",
        "\n",
        "for layer in base_model_2.layers[:-30]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_2.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[AUC(name='auc')]\n",
        ")\n",
        "\n",
        "callbacks_2 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint(\n",
        "        '/content/gdrive/MyDrive/scooter-parking-detector/models/result/resnet/best_stage2_resnet50_focused_improper.h5',\n",
        "        monitor='val_auc', save_best_only=True, mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"\\n🔹 Stage 2 (ResNet50) 학습 시작\")\n",
        "history_2 = model_2.fit(\n",
        "    train_gen_2,\n",
        "    validation_data=val_gen_2,\n",
        "    epochs=50,\n",
        "    class_weight=class_weight_2,\n",
        "    callbacks=callbacks_2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVH0hpUL5tHj",
        "outputId": "04a44e46-dc4e-4815-f2a9-38d8360b0d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 751 images belonging to 2 classes.\n",
            "Found 93 images belonging to 2 classes.\n",
            "\n",
            "🔹 Stage 2 (ResNet50) 학습 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step - auc: 0.4601 - loss: 1.5281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 802ms/step - auc: 0.4626 - loss: 1.5204 - val_auc: 0.3674 - val_loss: 0.7197 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - auc: 0.8144 - loss: 0.8470"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 364ms/step - auc: 0.8158 - loss: 0.8444 - val_auc: 0.3726 - val_loss: 0.7480 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - auc: 0.9074 - loss: 0.5575"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 518ms/step - auc: 0.9085 - loss: 0.5566 - val_auc: 0.3957 - val_loss: 0.8141 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - auc: 0.9509 - loss: 0.4286"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 363ms/step - auc: 0.9504 - loss: 0.4296 - val_auc: 0.4395 - val_loss: 0.9082 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - auc: 0.9794 - loss: 0.3537"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 520ms/step - auc: 0.9789 - loss: 0.3553 - val_auc: 0.4533 - val_loss: 0.9401 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - auc: 0.9890 - loss: 0.2883"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 359ms/step - auc: 0.9888 - loss: 0.2875 - val_auc: 0.4732 - val_loss: 0.9155 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - auc: 0.9954 - loss: 0.2306"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 495ms/step - auc: 0.9953 - loss: 0.2295 - val_auc: 0.5418 - val_loss: 0.7240 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - auc: 0.9962 - loss: 0.1644"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 494ms/step - auc: 0.9961 - loss: 0.1647 - val_auc: 0.8067 - val_loss: 0.5444 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 302ms/step - auc: 0.9980 - loss: 0.1224 - val_auc: 0.7556 - val_loss: 0.5786 - learning_rate: 1.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - auc: 0.9994 - loss: 0.0929"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 489ms/step - auc: 0.9994 - loss: 0.0926 - val_auc: 0.9258 - val_loss: 0.3749 - learning_rate: 1.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - auc: 0.9998 - loss: 0.0522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - auc: 0.9998 - loss: 0.0527 - val_auc: 0.9650 - val_loss: 0.2780 - learning_rate: 1.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 324ms/step - auc: 0.9996 - loss: 0.0618 - val_auc: 0.8696 - val_loss: 0.4659 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - auc: 0.9999 - loss: 0.0469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 362ms/step - auc: 0.9999 - loss: 0.0467 - val_auc: 0.9701 - val_loss: 0.2306 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - auc: 1.0000 - loss: 0.0257"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - auc: 1.0000 - loss: 0.0258 - val_auc: 0.9783 - val_loss: 0.1933 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - auc: 1.0000 - loss: 0.0228 - val_auc: 0.9470 - val_loss: 0.3053 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 312ms/step - auc: 0.9954 - loss: 0.1133 - val_auc: 0.9369 - val_loss: 0.3276 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 318ms/step - auc: 0.9997 - loss: 0.0598 - val_auc: 0.9751 - val_loss: 0.2140 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 308ms/step - auc: 1.0000 - loss: 0.0259 - val_auc: 0.9629 - val_loss: 0.2634 - learning_rate: 5.0000e-06\n",
            "Epoch 19/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 371ms/step - auc: 1.0000 - loss: 0.0213 - val_auc: 0.9738 - val_loss: 0.2248 - learning_rate: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 임계값 최적화"
      ],
      "metadata": {
        "id": "jDqz2Owdi6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ✅ 경로 설정\n",
        "val_dir = '/content/gdrive/MyDrive/dataset/cnn/val'\n",
        "model_stage1_path = '/content/gdrive/MyDrive/scooter-parking-detector/models/result/resnet/best_stage1_resnet50.h5'\n",
        "model_stage2_path = '/content/gdrive/MyDrive/scooter-parking-detector/models/result/resnet/best_stage2_resnet50_focused_improper.h5'\n",
        "# ✅ 모델 불러오기\n",
        "model_1 = load_model(model_stage1_path)\n",
        "model_2 = load_model(model_stage2_path)\n",
        "\n",
        "# ✅ 검증 데이터 로딩\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 검증 데이터 제너레이터\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 클래스 매핑 정보 출력 (검증 데이터 기준)\n",
        "label_map = val_gen.class_indices\n",
        "inv_map = {v: k for k, v in label_map.items()}\n",
        "print(\"\\n✅ 클래스 매핑 (검증 데이터셋의 실제 클래스 인덱스):\", inv_map)\n",
        "\n",
        "# --- 임계값 최적화: 검증 데이터 사용 ---\n",
        "\n",
        "# ✅ 전체 검증 이미지 및 라벨 수집\n",
        "print(\"\\n검증 데이터 수집 중...\")\n",
        "x_val_all, y_val_all = [], []\n",
        "for i in range(len(val_gen)):\n",
        "    x_batch, y_batch = val_gen[i]\n",
        "    x_val_all.extend(x_batch)\n",
        "    y_val_all.extend(y_batch)\n",
        "\n",
        "x_val_all = np.array(x_val_all)\n",
        "y_val_all = np.array(y_val_all)\n",
        "y_val_true = np.argmax(y_val_all, axis=1) # One-hot encoded y_val_all을 단일 클래스 인덱스로 변환\n",
        "print(f\"총 검증 이미지 수: {len(x_val_all)}\")\n",
        "\n",
        "\n",
        "# ✅ Stage 1 예측 확률 (검증 데이터에 대해)\n",
        "print(\"\\nStage 1 예측 수행 중 (검증 데이터)...\")\n",
        "\n",
        "stage1_val_preds = model_1.predict(x_val_all, verbose=1)\n",
        "\n",
        "\n",
        "# ✅ 임계값 최적화 (proper recall ≥ 0.85 조건하에 improper recall 최대화)\n",
        "best_threshold = None\n",
        "best_improper_recall = -1\n",
        "best_val_preds_for_threshold = None # 최적 임계값에서의 검증 데이터 예측 결과 저장\n",
        "\n",
        "thresholds = np.arange(0.01, 0.5, 0.01) # 0.01부터 0.49까지 0.01 간격으로\n",
        "RECALL_MIN_PROPER = 0.85\n",
        "\n",
        "print(\"\\n🔍 Threshold 탐색 시작 (proper recall ≥ 0.85 조건 하에서 improper recall 최대화 - 검증 데이터 사용)\")\n",
        "\n",
        "for t in thresholds:\n",
        "    # Stage 1 예측을 이진화: t보다 크면 1_kickboard, 아니면 0_no_kickboard\n",
        "    stage1_val_binary = (stage1_val_preds > t).astype(int).flatten()\n",
        "\n",
        "    # Stage 1에서 '1' (has_kickboard)으로 분류된 이미지의 인덱스\n",
        "    stage2_val_indices = np.where(stage1_val_binary == 1)[0]\n",
        "    x_val_stage2 = x_val_all[stage2_val_indices]\n",
        "\n",
        "    # 최종 예측 결과 배열 초기화: 기본값은 Stage 1에서 0(no_kickboard)으로 분류된 'noise' (최종 클래스 인덱스: 1)\n",
        "    final_val_preds = np.full_like(stage1_val_binary, fill_value=1)\n",
        "\n",
        "    # Stage 2로 넘어갈 이미지가 있을 경우 Stage 2 모델 예측 수행\n",
        "    if len(x_val_stage2) > 0:\n",
        "        stage2_val_preds = model_2.predict(x_val_stage2, verbose=0)\n",
        "        # Stage 2는 0:improper, 1:proper 입니다.\n",
        "        stage2_val_classes = np.argmax(stage2_val_preds, axis=1) # Stage 2의 예측 클래스 (0 또는 1)\n",
        "\n",
        "        # Stage 2 예측을 최종 3개 클래스 (0:improper, 1:noise, 2:proper)에 매핑\n",
        "        # Stage 2가 0(improper)으로 예측하면 최종 0(improper)\n",
        "        # Stage 2가 1(proper)으로 예측하면 최종 2(proper)\n",
        "        final_val_preds[stage2_val_indices] = np.where(stage2_val_classes == 0, 0, 2)\n",
        "    # else 블록은 위에 final_val_preds 초기화로 이미 처리됨: Stage 2로 넘어갈 이미지가 없으면 모두 noise(1)\n",
        "\n",
        "    # 분류 리포트 생성 및 재현율 추출\n",
        "    report = classification_report(y_val_true, final_val_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    # 'proper'와 'improper' 클래스에 해당하는 재현율 추출\n",
        "    # inv_map (0: improper, 1: noise, 2: proper)에 따라\n",
        "    # proper는 '2', improper는 '0'\n",
        "    proper_recall = report.get('2', {}).get('recall', 0.0) # proper (클래스 2)의 recall\n",
        "    improper_recall = report.get('0', {}).get('recall', 0.0) # improper (클래스 0)의 recall\n",
        "\n",
        "    if proper_recall >= RECALL_MIN_PROPER:\n",
        "        print(f\" - threshold {t:.2f}: proper recall = {proper_recall:.4f}, improper recall = {improper_recall:.4f}\")\n",
        "        if improper_recall > best_improper_recall:\n",
        "            best_improper_recall = improper_recall\n",
        "            best_threshold = t\n",
        "            best_val_preds_for_threshold = final_val_preds.copy()\n",
        "\n",
        "# ✅ 최적 임계값 결과 출력 (검증 데이터 기준)\n",
        "print(\"\\n--- 임계값 최적화 결과 ---\")\n",
        "if best_threshold is not None:\n",
        "    print(f\"\\n✅ 최적 threshold (검증 데이터 기준): {best_threshold:.2f} (improper recall = {best_improper_recall:.4f}, proper recall ≥ {RECALL_MIN_PROPER:.2f})\")\n",
        "    print(\"\\n✅ Classification Report (최적 임계값 적용된 검증 데이터 결과)\")\n",
        "    print(classification_report(y_val_true, best_val_preds_for_threshold, target_names=['improper', 'noise', 'proper'], zero_division=0))\n",
        "    print(\"\\n✅ Confusion Matrix (최적 임계값 적용된 검증 데이터 결과)\")\n",
        "    print(confusion_matrix(y_val_true, best_val_preds_for_threshold))\n",
        "\n",
        "    # AUC 계산\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    y_val_true_one_hot = to_categorical(y_val_true, num_classes=3)\n",
        "    best_val_preds_for_threshold_one_hot = to_categorical(best_val_preds_for_threshold, num_classes=3)\n",
        "    auc = roc_auc_score(y_val_true_one_hot, best_val_preds_for_threshold_one_hot, multi_class='ovr')\n",
        "    print(f\"\\n✅ AUC (검증 데이터, macro): {auc:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n⚠️ proper recall ≥ {RECALL_MIN_PROPER:.2f}를 만족하는 threshold가 검증 데이터에서 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL6aFTbpcrp_",
        "outputId": "b70c6c71-7ba6-4b26-c3bb-3bf9a33aadb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 109 images belonging to 3 classes.\n",
            "\n",
            "✅ 클래스 매핑 (검증 데이터셋의 실제 클래스 인덱스): {0: 'improper', 1: 'noise', 2: 'proper'}\n",
            "\n",
            "검증 데이터 수집 중...\n",
            "총 검증 이미지 수: 109\n",
            "\n",
            "Stage 1 예측 수행 중 (검증 데이터)...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 995ms/step\n",
            "\n",
            "🔍 Threshold 탐색 시작 (proper recall ≥ 0.85 조건 하에서 improper recall 최대화 - 검증 데이터 사용)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 124 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7a563c47aa20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - threshold 0.01: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.02: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.03: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.04: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.05: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.06: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.07: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.08: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.09: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.10: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.11: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.12: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.13: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.14: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.15: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.16: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.17: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.18: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.19: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.20: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.21: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.22: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.23: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.24: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.25: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.26: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.27: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.28: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.29: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.30: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.31: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.32: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.33: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.34: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.35: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.36: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.37: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.38: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.39: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.40: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.41: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.42: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.43: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.44: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.45: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.46: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.47: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.48: proper recall = 1.0000, improper recall = 0.9677\n",
            " - threshold 0.49: proper recall = 1.0000, improper recall = 0.9677\n",
            "\n",
            "--- 임계값 최적화 결과 ---\n",
            "\n",
            "✅ 최적 threshold (검증 데이터 기준): 0.01 (improper recall = 0.9677, proper recall ≥ 0.85)\n",
            "\n",
            "✅ Classification Report (최적 임계값 적용된 검증 데이터 결과)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    improper       0.77      0.97      0.86        31\n",
            "       noise       1.00      0.07      0.12        15\n",
            "      proper       0.91      1.00      0.95        63\n",
            "\n",
            "    accuracy                           0.86       109\n",
            "   macro avg       0.89      0.68      0.65       109\n",
            "weighted avg       0.88      0.86      0.81       109\n",
            "\n",
            "\n",
            "✅ Confusion Matrix (최적 임계값 적용된 검증 데이터 결과)\n",
            "[[30  0  1]\n",
            " [ 9  1  5]\n",
            " [ 0  0 63]]\n",
            "\n",
            "✅ AUC (검증 데이터, macro): 0.7981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 시각화"
      ],
      "metadata": {
        "id": "NZwHKx1BkIGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ✅ 클래스 이름\n",
        "class_names = ['improper', 'noise', 'proper']\n",
        "\n",
        "# ✅ 혼동행렬 정의 (직접 입력한 경우)\n",
        "cm = np.array([[30 ,0, 1],\n",
        " [ 9, 1, 5],\n",
        " [ 0,  0, 63]])\n",
        "\n",
        "# ✅ 시각화\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "WFiBPZMDkKAM",
        "outputId": "e7f10525-fc85-4bce-f754-aa686aaba6f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}