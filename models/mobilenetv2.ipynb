{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyomee2/scooter-parking-detector/blob/main/models/mobilenetv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKqGk6QIxiDv"
      },
      "source": [
        "## 구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGz6wFzHaMmM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. tensorflow 설치"
      ],
      "metadata": {
        "id": "c4raI73gO6DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMZ5pTbwcGr_"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from math import floor\n",
        "\n",
        "# 수정된 경로: 모두 Google Drive 내에서 작업\n",
        "original_base = '/content/gdrive/MyDrive/dataset/cnn'\n",
        "combined_temp = '/content/gdrive/MyDrive/dataset/cnn_2stages/_temp_combined'\n",
        "new_base = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "class_names = ['improper', 'proper', 'noise']\n",
        "random.seed(42)\n",
        "\n",
        "# cnn 데이터셋 통합 후 재분할 준비\n",
        "# combined_temp 폴더 초기화 및 생성\n",
        "if os.path.exists(combined_temp):\n",
        "    shutil.rmtree(combined_temp)\n",
        "os.makedirs(combined_temp, exist_ok=True)\n",
        "\n",
        "for cls in class_names:\n",
        "    os.makedirs(os.path.join(combined_temp, cls), exist_ok=True)\n",
        "    for split in splits:\n",
        "        src = os.path.join(original_base, split, cls)\n",
        "        if os.path.exists(src):\n",
        "            for f in os.listdir(src):\n",
        "                src_path = os.path.join(src, f)\n",
        "                if os.path.isfile(src_path):\n",
        "                    # 원본 split 정보를 파일명에 붙여서 저장 (ex: train_abc.jpg)\n",
        "                    shutil.copy(src_path, os.path.join(combined_temp, cls, f\"{split}_{f}\"))\n",
        "\n",
        "print(\"✅ CNN 데이터셋 통합 완료!\")\n",
        "\n",
        "# 재분할 및 stage별 폴더 생성 함수\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def split_and_copy(src_dir, dst_map, ratios):\n",
        "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
        "    random.shuffle(files)\n",
        "    total = len(files)\n",
        "    train_end = floor(ratios[0] * total)\n",
        "    val_end = train_end + floor(ratios[1] * total)\n",
        "\n",
        "    for i, phase in enumerate(['train', 'val', 'test']):\n",
        "        phase_files = files[:train_end] if phase == 'train' else \\\n",
        "                      files[train_end:val_end] if phase == 'val' else \\\n",
        "                      files[val_end:]\n",
        "        dst_dir = dst_map[phase]\n",
        "        ensure_dir(dst_dir)\n",
        "        for fname in phase_files:\n",
        "            shutil.copy(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
        "\n",
        "# stage1 / stage2 클래스 매핑\n",
        "stage1_map = {\n",
        "    'noise': '0_no_kickboard',\n",
        "    'improper': '1_has_kickboard',\n",
        "    'proper': '1_has_kickboard'\n",
        "}\n",
        "\n",
        "stage2_map = {\n",
        "    'improper': '0_improper',\n",
        "    'proper': '2_proper'\n",
        "}\n",
        "\n",
        "# stage별 분할 및 저장\n",
        "for cls in class_names:\n",
        "    src_dir = os.path.join(combined_temp, cls)\n",
        "\n",
        "    # Stage 1 (noise 포함)\n",
        "    dst_stage1 = {\n",
        "        'train': os.path.join(new_base, 'stage1', 'train', stage1_map[cls]),\n",
        "        'val': os.path.join(new_base, 'stage1', 'val', stage1_map[cls]),\n",
        "        'test': os.path.join(new_base, 'stage1', 'test', stage1_map[cls])\n",
        "    }\n",
        "    split_and_copy(src_dir, dst_stage1, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "    # Stage 2 (noise 제외)\n",
        "    if cls != 'noise':\n",
        "        dst_stage2 = {\n",
        "            'train': os.path.join(new_base, 'stage2', 'train', stage2_map[cls]),\n",
        "            'val': os.path.join(new_base, 'stage2', 'val', stage2_map[cls]),\n",
        "            'test': os.path.join(new_base, 'stage2', 'test', stage2_map[cls])\n",
        "        }\n",
        "        split_and_copy(src_dir, dst_stage2, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "print(\"✅ stage1, stage2 데이터셋 분할 및 생성 완료!\")"
      ],
      "metadata": {
        "id": "oM4fES1-SKD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 이상 이미지 제거"
      ],
      "metadata": {
        "id": "XnjY_hTbhtSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_dataset(directory):\n",
        "    valid_exts = ['.jpg', '.jpeg', '.png']\n",
        "    removed_files = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext not in valid_exts:\n",
        "                file_path = os.path.join(root, fname)\n",
        "                removed_files.append(file_path)\n",
        "                os.remove(file_path)\n",
        "\n",
        "    return removed_files\n",
        "\n",
        "# 데이터셋 경로 정리\n",
        "removed = clean_dataset('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"✅ 삭제된 비이미지 파일 개수: {len(removed)}\")\n"
      ],
      "metadata": {
        "id": "gD04r0o2Sa7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def clean_corrupted_images(directory):\n",
        "    corrupted = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext in ['.jpg', '.jpeg', '.png']:\n",
        "                fpath = os.path.join(root, fname)\n",
        "                try:\n",
        "                    img = Image.open(fpath)\n",
        "                    img.verify()  # 파일이 진짜 이미지인지 검사\n",
        "                except Exception:\n",
        "                    corrupted.append(fpath)\n",
        "                    os.remove(fpath)\n",
        "    return corrupted\n",
        "\n",
        "# 실제 이미지 열어서 검사\n",
        "bad_files = clean_corrupted_images('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"🧹 삭제된 손상된 이미지 파일 개수: {len(bad_files)}\")\n"
      ],
      "metadata": {
        "id": "OQBdAjRd32Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 학습"
      ],
      "metadata": {
        "id": "CUSRrcmWh-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 경로 설정\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage1_train = os.path.join(base_path, 'stage1', 'train')\n",
        "stage1_val = os.path.join(base_path, 'stage1', 'val')\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# ✅ 데이터 증강 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ Stage 1: 킥보드 유무 이진 분류\n",
        "train_gen_1 = datagen.flow_from_directory(stage1_train, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "val_gen_1 = val_datagen.flow_from_directory(stage1_val, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "\n",
        "base_model_1 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x1 = GlobalAveragePooling2D()(base_model_1.output)\n",
        "out1 = Dense(1, activation='sigmoid')(x1)\n",
        "model_1 = Model(inputs=base_model_1.input, outputs=out1)\n",
        "\n",
        "for layer in base_model_1.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_1.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
        "\n",
        "callbacks_1 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint('/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5',\n",
        "                    monitor='val_auc', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "print(\"\\n🔹 Stage 1 학습 시작\")\n",
        "history_1 = model_1.fit(train_gen_1, validation_data=val_gen_1, epochs=50, callbacks=callbacks_1)\n",
        "\n",
        "\n",
        "# ✅ 경로 설정\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# ✅ 데이터 증강 설정\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "train_gen_2 = train_datagen.flow_from_directory(\n",
        "    stage2_train,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # one-hot 인코딩\n",
        "    shuffle=True\n",
        ")\n",
        "val_gen_2 = val_datagen.flow_from_directory(\n",
        "    stage2_val,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 클래스 가중치 설정\n",
        "class_weight_2 = {\n",
        "    0: 10.0,  # improper\n",
        "    1: 1.0    # proper\n",
        "}\n",
        "\n",
        "# ✅ 모델 구성\n",
        "base_model_2 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x = GlobalAveragePooling2D()(base_model_2.output)\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "model_2 = Model(inputs=base_model_2.input, outputs=out)\n",
        "\n",
        "# ✅ 마지막 60개 레이어만 fine-tuning\n",
        "for layer in base_model_2.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_2.layers[-60:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# ✅ 컴파일\n",
        "model_2.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# ✅ 콜백 설정\n",
        "callbacks_2 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint(\n",
        "        '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5',\n",
        "        monitor='val_auc', save_best_only=True, mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "# ✅ 학습\n",
        "print(\"\\n🔹 Stage 2 학습 시작\")\n",
        "history_2 = model_2.fit(train_gen_2,\n",
        "    validation_data=val_gen_2,\n",
        "    epochs=50,\n",
        "    class_weight=class_weight_2,\n",
        "    callbacks=callbacks_2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "wp3LAXsvpnWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 임계값 최적화"
      ],
      "metadata": {
        "id": "jDqz2Owdi6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ✅ 경로 설정\n",
        "val_dir = '/content/gdrive/MyDrive/dataset/cnn/val'\n",
        "model_stage1_path = '/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5'\n",
        "model_stage2_path = '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5'\n",
        "# ✅ 모델 불러오기\n",
        "model_1 = load_model(model_stage1_path)\n",
        "model_2 = load_model(model_stage2_path)\n",
        "\n",
        "# ✅ 검증 데이터 로딩\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 검증 데이터 제너레이터\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 클래스 매핑 정보 출력 (검증 데이터 기준)\n",
        "label_map = val_gen.class_indices\n",
        "inv_map = {v: k for k, v in label_map.items()}\n",
        "print(\"\\n✅ 클래스 매핑 (검증 데이터셋의 실제 클래스 인덱스):\", inv_map)\n",
        "\n",
        "# --- 임계값 최적화: 검증 데이터 사용 ---\n",
        "\n",
        "# ✅ 전체 검증 이미지 및 라벨 수집\n",
        "print(\"\\n검증 데이터 수집 중...\")\n",
        "x_val_all, y_val_all = [], []\n",
        "for i in range(len(val_gen)):\n",
        "    x_batch, y_batch = val_gen[i]\n",
        "    x_val_all.extend(x_batch)\n",
        "    y_val_all.extend(y_batch)\n",
        "\n",
        "x_val_all = np.array(x_val_all)\n",
        "y_val_all = np.array(y_val_all)\n",
        "y_val_true = np.argmax(y_val_all, axis=1) # One-hot encoded y_val_all을 단일 클래스 인덱스로 변환\n",
        "print(f\"총 검증 이미지 수: {len(x_val_all)}\")\n",
        "\n",
        "\n",
        "# ✅ Stage 1 예측 확률 (검증 데이터에 대해)\n",
        "print(\"\\nStage 1 예측 수행 중 (검증 데이터)...\")\n",
        "\n",
        "stage1_val_preds = model_1.predict(x_val_all, verbose=1)\n",
        "\n",
        "\n",
        "# ✅ 임계값 최적화 (proper recall ≥ 0.85 조건하에 improper recall 최대화)\n",
        "best_threshold = None\n",
        "best_improper_recall = -1\n",
        "best_val_preds_for_threshold = None # 최적 임계값에서의 검증 데이터 예측 결과 저장\n",
        "\n",
        "thresholds = np.arange(0.01, 0.5, 0.01) # 0.01부터 0.49까지 0.01 간격으로\n",
        "RECALL_MIN_PROPER = 0.85\n",
        "\n",
        "print(\"\\n🔍 Threshold 탐색 시작 (proper recall ≥ 0.85 조건 하에서 improper recall 최대화 - 검증 데이터 사용)\")\n",
        "\n",
        "for t in thresholds:\n",
        "    # Stage 1 예측을 이진화: t보다 크면 1_kickboard, 아니면 0_no_kickboard\n",
        "    stage1_val_binary = (stage1_val_preds > t).astype(int).flatten()\n",
        "\n",
        "    # Stage 1에서 '1' (has_kickboard)으로 분류된 이미지의 인덱스\n",
        "    stage2_val_indices = np.where(stage1_val_binary == 1)[0]\n",
        "    x_val_stage2 = x_val_all[stage2_val_indices]\n",
        "\n",
        "    # 최종 예측 결과 배열 초기화: 기본값은 Stage 1에서 0(no_kickboard)으로 분류된 'noise' (최종 클래스 인덱스: 1)\n",
        "    final_val_preds = np.full_like(stage1_val_binary, fill_value=1)\n",
        "\n",
        "    # Stage 2로 넘어갈 이미지가 있을 경우 Stage 2 모델 예측 수행\n",
        "    if len(x_val_stage2) > 0:\n",
        "        stage2_val_preds = model_2.predict(x_val_stage2, verbose=0)\n",
        "        # Stage 2는 0:improper, 1:proper 입니다.\n",
        "        stage2_val_classes = np.argmax(stage2_val_preds, axis=1) # Stage 2의 예측 클래스 (0 또는 1)\n",
        "\n",
        "        # Stage 2 예측을 최종 3개 클래스 (0:improper, 1:noise, 2:proper)에 매핑\n",
        "        # Stage 2가 0(improper)으로 예측하면 최종 0(improper)\n",
        "        # Stage 2가 1(proper)으로 예측하면 최종 2(proper)\n",
        "        final_val_preds[stage2_val_indices] = np.where(stage2_val_classes == 0, 0, 2)\n",
        "    # else 블록은 위에 final_val_preds 초기화로 이미 처리됨: Stage 2로 넘어갈 이미지가 없으면 모두 noise(1)\n",
        "\n",
        "    # 분류 리포트 생성 및 재현율 추출\n",
        "    report = classification_report(y_val_true, final_val_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    # 'proper'와 'improper' 클래스에 해당하는 재현율 추출\n",
        "    # inv_map (0: improper, 1: noise, 2: proper)에 따라\n",
        "    # proper는 '2', improper는 '0'\n",
        "    proper_recall = report.get('2', {}).get('recall', 0.0) # proper (클래스 2)의 recall\n",
        "    improper_recall = report.get('0', {}).get('recall', 0.0) # improper (클래스 0)의 recall\n",
        "\n",
        "    if proper_recall >= RECALL_MIN_PROPER:\n",
        "        print(f\" - threshold {t:.2f}: proper recall = {proper_recall:.4f}, improper recall = {improper_recall:.4f}\")\n",
        "        if improper_recall > best_improper_recall:\n",
        "            best_improper_recall = improper_recall\n",
        "            best_threshold = t\n",
        "            best_val_preds_for_threshold = final_val_preds.copy()\n",
        "\n",
        "# ✅ 최적 임계값 결과 출력 (검증 데이터 기준)\n",
        "print(\"\\n--- 임계값 최적화 결과 ---\")\n",
        "if best_threshold is not None:\n",
        "    print(f\"\\n✅ 최적 threshold (검증 데이터 기준): {best_threshold:.2f} (improper recall = {best_improper_recall:.4f}, proper recall ≥ {RECALL_MIN_PROPER:.2f})\")\n",
        "    print(\"\\n✅ Classification Report (최적 임계값 적용된 검증 데이터 결과)\")\n",
        "    print(classification_report(y_val_true, best_val_preds_for_threshold, target_names=['improper', 'noise', 'proper'], zero_division=0))\n",
        "    print(\"\\n✅ Confusion Matrix (최적 임계값 적용된 검증 데이터 결과)\")\n",
        "    print(confusion_matrix(y_val_true, best_val_preds_for_threshold))\n",
        "\n",
        "    # AUC 계산\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    y_val_true_one_hot = to_categorical(y_val_true, num_classes=3)\n",
        "    best_val_preds_for_threshold_one_hot = to_categorical(best_val_preds_for_threshold, num_classes=3)\n",
        "    auc = roc_auc_score(y_val_true_one_hot, best_val_preds_for_threshold_one_hot, multi_class='ovr')\n",
        "    print(f\"\\n✅ AUC (검증 데이터, macro): {auc:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n⚠️ proper recall ≥ {RECALL_MIN_PROPER:.2f}를 만족하는 threshold가 검증 데이터에서 없습니다.\")"
      ],
      "metadata": {
        "id": "nL6aFTbpcrp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 시각화"
      ],
      "metadata": {
        "id": "NZwHKx1BkIGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ✅ 클래스 이름\n",
        "class_names = ['improper', 'noise', 'proper']\n",
        "\n",
        "# ✅ 혼동행렬 정의 (직접 입력한 경우)\n",
        "cm = np.array([[23 ,0,  8],\n",
        " [ 0, 15,  0],\n",
        " [ 0,  0, 63]])\n",
        "\n",
        "# ✅ 시각화\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WFiBPZMDkKAM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}