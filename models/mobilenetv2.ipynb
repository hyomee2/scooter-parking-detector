{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyomee2/scooter-parking-detector/blob/main/models/mobilenetv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKqGk6QIxiDv"
      },
      "source": [
        "## 구글 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGz6wFzHaMmM",
        "outputId": "ff0d9139-f32f-4e72-c8e2-fba5e1bbcb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. tensorflow 설치"
      ],
      "metadata": {
        "id": "c4raI73gO6DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMZ5pTbwcGr_",
        "outputId": "cf454d0d-6440-4438-c1e6-8bf15ef529af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from math import floor\n",
        "\n",
        "# 수정된 경로: 모두 Google Drive 내에서 작업\n",
        "original_base = '/content/gdrive/MyDrive/dataset/cnn'\n",
        "combined_temp = '/content/gdrive/MyDrive/dataset/cnn_2stages/_temp_combined'\n",
        "new_base = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "class_names = ['improper', 'proper', 'noise']\n",
        "random.seed(42)\n",
        "\n",
        "# cnn 데이터셋 통합 후 재분할 준비\n",
        "# combined_temp 폴더 초기화 및 생성\n",
        "if os.path.exists(combined_temp):\n",
        "    shutil.rmtree(combined_temp)\n",
        "os.makedirs(combined_temp, exist_ok=True)\n",
        "\n",
        "for cls in class_names:\n",
        "    os.makedirs(os.path.join(combined_temp, cls), exist_ok=True)\n",
        "    for split in splits:\n",
        "        src = os.path.join(original_base, split, cls)\n",
        "        if os.path.exists(src):\n",
        "            for f in os.listdir(src):\n",
        "                src_path = os.path.join(src, f)\n",
        "                if os.path.isfile(src_path):\n",
        "                    # 원본 split 정보를 파일명에 붙여서 저장 (ex: train_abc.jpg)\n",
        "                    shutil.copy(src_path, os.path.join(combined_temp, cls, f\"{split}_{f}\"))\n",
        "\n",
        "print(\"✅ CNN 데이터셋 통합 완료!\")\n",
        "\n",
        "# 재분할 및 stage별 폴더 생성 함수\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def split_and_copy(src_dir, dst_map, ratios):\n",
        "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
        "    random.shuffle(files)\n",
        "    total = len(files)\n",
        "    train_end = floor(ratios[0] * total)\n",
        "    val_end = train_end + floor(ratios[1] * total)\n",
        "\n",
        "    for i, phase in enumerate(['train', 'val', 'test']):\n",
        "        phase_files = files[:train_end] if phase == 'train' else \\\n",
        "                      files[train_end:val_end] if phase == 'val' else \\\n",
        "                      files[val_end:]\n",
        "        dst_dir = dst_map[phase]\n",
        "        ensure_dir(dst_dir)\n",
        "        for fname in phase_files:\n",
        "            shutil.copy(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
        "\n",
        "# stage1 / stage2 클래스 매핑\n",
        "stage1_map = {\n",
        "    'noise': '0_no_kickboard',\n",
        "    'improper': '1_has_kickboard',\n",
        "    'proper': '1_has_kickboard'\n",
        "}\n",
        "\n",
        "stage2_map = {\n",
        "    'improper': '0_improper',\n",
        "    'proper': '2_proper'\n",
        "}\n",
        "\n",
        "# stage별 분할 및 저장\n",
        "for cls in class_names:\n",
        "    src_dir = os.path.join(combined_temp, cls)\n",
        "\n",
        "    # Stage 1 (noise 포함)\n",
        "    dst_stage1 = {\n",
        "        'train': os.path.join(new_base, 'stage1', 'train', stage1_map[cls]),\n",
        "        'val': os.path.join(new_base, 'stage1', 'val', stage1_map[cls]),\n",
        "        'test': os.path.join(new_base, 'stage1', 'test', stage1_map[cls])\n",
        "    }\n",
        "    split_and_copy(src_dir, dst_stage1, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "    # Stage 2 (noise 제외)\n",
        "    if cls != 'noise':\n",
        "        dst_stage2 = {\n",
        "            'train': os.path.join(new_base, 'stage2', 'train', stage2_map[cls]),\n",
        "            'val': os.path.join(new_base, 'stage2', 'val', stage2_map[cls]),\n",
        "            'test': os.path.join(new_base, 'stage2', 'test', stage2_map[cls])\n",
        "        }\n",
        "        split_and_copy(src_dir, dst_stage2, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "print(\"✅ stage1, stage2 데이터셋 분할 및 생성 완료!\")"
      ],
      "metadata": {
        "id": "oM4fES1-SKD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78de639d-d4ed-4da0-b719-f01d22f86f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mobilenet 데이터셋 통합 완료!\n",
            "✅ stage1, stage2 데이터셋 분할 및 생성 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 이상 이미지 제거"
      ],
      "metadata": {
        "id": "XnjY_hTbhtSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_dataset(directory):\n",
        "    valid_exts = ['.jpg', '.jpeg', '.png']\n",
        "    removed_files = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext not in valid_exts:\n",
        "                file_path = os.path.join(root, fname)\n",
        "                removed_files.append(file_path)\n",
        "                os.remove(file_path)\n",
        "\n",
        "    return removed_files\n",
        "\n",
        "# 데이터셋 경로 정리\n",
        "removed = clean_dataset('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"✅ 삭제된 비이미지 파일 개수: {len(removed)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b3923d-be82-4da6-d471-994f00b90da8",
        "id": "gD04r0o2Sa7S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 삭제된 비이미지 파일 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def clean_corrupted_images(directory):\n",
        "    corrupted = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext in ['.jpg', '.jpeg', '.png']:\n",
        "                fpath = os.path.join(root, fname)\n",
        "                try:\n",
        "                    img = Image.open(fpath)\n",
        "                    img.verify()  # 파일이 진짜 이미지인지 검사\n",
        "                except Exception:\n",
        "                    corrupted.append(fpath)\n",
        "                    os.remove(fpath)\n",
        "    return corrupted\n",
        "\n",
        "# 실제 이미지 열어서 검사\n",
        "bad_files = clean_corrupted_images('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"🧹 삭제된 손상된 이미지 파일 개수: {len(bad_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQBdAjRd32Oj",
        "outputId": "8bb2b01b-1117-4aa5-8889-4cf9bb4b69f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 삭제된 손상된 이미지 파일 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 모델 학습"
      ],
      "metadata": {
        "id": "CUSRrcmWh-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "5Hvz3N85uTQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 경로 설정\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage1_train = os.path.join(base_path, 'stage1', 'train')\n",
        "stage1_val = os.path.join(base_path, 'stage1', 'val')\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# ✅ 데이터 증강 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ Stage 1: 킥보드 유무 이진 분류\n",
        "train_gen_1 = datagen.flow_from_directory(stage1_train, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "val_gen_1 = val_datagen.flow_from_directory(stage1_val, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "\n",
        "base_model_1 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x1 = GlobalAveragePooling2D()(base_model_1.output)\n",
        "out1 = Dense(1, activation='sigmoid')(x1)\n",
        "model_1 = Model(inputs=base_model_1.input, outputs=out1)\n",
        "\n",
        "for layer in base_model_1.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_1.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
        "\n",
        "callbacks_1 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint('/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5',\n",
        "                    monitor='val_auc', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "print(\"\\n🔹 Stage 1 학습 시작\")\n",
        "history_1 = model_1.fit(train_gen_1, validation_data=val_gen_1, epochs=50, callbacks=callbacks_1)\n",
        "\n",
        "\n",
        "# ✅ 경로 설정\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# ✅ 데이터 증강 설정\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ✅ 데이터 로딩\n",
        "train_gen_2 = train_datagen.flow_from_directory(\n",
        "    stage2_train,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # one-hot 인코딩\n",
        "    shuffle=True\n",
        ")\n",
        "val_gen_2 = val_datagen.flow_from_directory(\n",
        "    stage2_val,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 클래스 가중치 설정\n",
        "class_weight_2 = {\n",
        "    0: 10.0,  # improper\n",
        "    1: 1.0    # proper\n",
        "}\n",
        "\n",
        "# ✅ 모델 구성\n",
        "base_model_2 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x = GlobalAveragePooling2D()(base_model_2.output)\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "model_2 = Model(inputs=base_model_2.input, outputs=out)\n",
        "\n",
        "# ✅ 마지막 60개 레이어만 fine-tuning\n",
        "for layer in base_model_2.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_2.layers[-60:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# ✅ 컴파일\n",
        "model_2.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# ✅ 콜백 설정\n",
        "callbacks_2 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint(\n",
        "        '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5',\n",
        "        monitor='val_auc', save_best_only=True, mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "# ✅ 학습\n",
        "print(\"\\n🔹 Stage 2 학습 시작\")\n",
        "history_2 = model_2.fit(train_gen_2,\n",
        "    validation_data=val_gen_2,\n",
        "    epochs=50,\n",
        "    class_weight=class_weight_2,\n",
        "    callbacks=callbacks_2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp3LAXsvpnWo",
        "outputId": "44be8d2b-ab0e-4be4-ddfc-92096eaabb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 871 images belonging to 2 classes.\n",
            "Found 108 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "🔹 Stage 1 학습 시작\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - auc: 0.5793 - loss: 0.6663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 11s/step - auc: 0.5819 - loss: 0.6651 - val_auc: 0.7907 - val_loss: 0.5402 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - auc: 0.9122 - loss: 0.4867"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 825ms/step - auc: 0.9121 - loss: 0.4859 - val_auc: 0.8935 - val_loss: 0.5458 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - auc: 0.9551 - loss: 0.3637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 812ms/step - auc: 0.9552 - loss: 0.3626 - val_auc: 0.9362 - val_loss: 0.6343 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - auc: 0.9796 - loss: 0.2648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 774ms/step - auc: 0.9796 - loss: 0.2641 - val_auc: 0.9659 - val_loss: 0.7247 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - auc: 0.9864 - loss: 0.2011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 795ms/step - auc: 0.9866 - loss: 0.2007 - val_auc: 0.9785 - val_loss: 0.8026 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - auc: 0.9901 - loss: 0.1699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 758ms/step - auc: 0.9902 - loss: 0.1697 - val_auc: 0.9849 - val_loss: 0.8235 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - auc: 0.9963 - loss: 0.1382"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 846ms/step - auc: 0.9962 - loss: 0.1381 - val_auc: 0.9864 - val_loss: 0.7919 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - auc: 0.9986 - loss: 0.1140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 829ms/step - auc: 0.9985 - loss: 0.1140 - val_auc: 0.9878 - val_loss: 0.7936 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - auc: 0.9972 - loss: 0.1097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 834ms/step - auc: 0.9972 - loss: 0.1095 - val_auc: 0.9900 - val_loss: 0.7575 - learning_rate: 1.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - auc: 0.9984 - loss: 0.0973"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 789ms/step - auc: 0.9984 - loss: 0.0973 - val_auc: 0.9925 - val_loss: 0.7440 - learning_rate: 1.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - auc: 0.9977 - loss: 0.0868"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 832ms/step - auc: 0.9978 - loss: 0.0867 - val_auc: 0.9943 - val_loss: 0.7092 - learning_rate: 1.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 788ms/step - auc: 0.9991 - loss: 0.0757 - val_auc: 0.9943 - val_loss: 0.7042 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722ms/step - auc: 0.9995 - loss: 0.0655 - val_auc: 0.9939 - val_loss: 0.6913 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - auc: 0.9994 - loss: 0.0684"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 808ms/step - auc: 0.9994 - loss: 0.0682 - val_auc: 0.9961 - val_loss: 0.6697 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - auc: 0.9998 - loss: 0.0511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 843ms/step - auc: 0.9998 - loss: 0.0512 - val_auc: 0.9975 - val_loss: 0.6648 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 784ms/step - auc: 0.9999 - loss: 0.0480 - val_auc: 0.9975 - val_loss: 0.6309 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - auc: 0.9996 - loss: 0.0477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 802ms/step - auc: 0.9996 - loss: 0.0478 - val_auc: 0.9986 - val_loss: 0.6049 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 799ms/step - auc: 0.9998 - loss: 0.0433 - val_auc: 0.9986 - val_loss: 0.5600 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 754ms/step - auc: 1.0000 - loss: 0.0377 - val_auc: 0.9986 - val_loss: 0.5479 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 753ms/step - auc: 1.0000 - loss: 0.0352 - val_auc: 0.9986 - val_loss: 0.5268 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675ms/step - auc: 1.0000 - loss: 0.0339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 795ms/step - auc: 1.0000 - loss: 0.0338 - val_auc: 0.9989 - val_loss: 0.4842 - learning_rate: 5.0000e-06\n",
            "Epoch 22/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 744ms/step - auc: 1.0000 - loss: 0.0315 - val_auc: 0.9989 - val_loss: 0.4571 - learning_rate: 5.0000e-06\n",
            "Epoch 23/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 779ms/step - auc: 0.9999 - loss: 0.0324 - val_auc: 0.9989 - val_loss: 0.4292 - learning_rate: 5.0000e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - auc: 1.0000 - loss: 0.0326"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 774ms/step - auc: 1.0000 - loss: 0.0325 - val_auc: 0.9996 - val_loss: 0.4032 - learning_rate: 5.0000e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 767ms/step - auc: 1.0000 - loss: 0.0278 - val_auc: 0.9996 - val_loss: 0.3791 - learning_rate: 5.0000e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722ms/step - auc: 1.0000 - loss: 0.0250 - val_auc: 0.9996 - val_loss: 0.3631 - learning_rate: 5.0000e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 768ms/step - auc: 1.0000 - loss: 0.0267 - val_auc: 0.9993 - val_loss: 0.3494 - learning_rate: 5.0000e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 779ms/step - auc: 1.0000 - loss: 0.0289 - val_auc: 0.9996 - val_loss: 0.3287 - learning_rate: 2.5000e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 727ms/step - auc: 1.0000 - loss: 0.0259 - val_auc: 0.9996 - val_loss: 0.3083 - learning_rate: 2.5000e-06\n",
            "Found 751 images belonging to 2 classes.\n",
            "Found 93 images belonging to 2 classes.\n",
            "\n",
            "🔹 Stage 2 학습 시작\n",
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - auc: 0.3780 - loss: 2.1322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 11s/step - auc: 0.3798 - loss: 2.1315 - val_auc: 0.4634 - val_loss: 0.9245 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - auc: 0.5292 - loss: 1.6559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 730ms/step - auc: 0.5286 - loss: 1.6531 - val_auc: 0.6472 - val_loss: 0.6867 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - auc: 0.5625 - loss: 1.3696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 749ms/step - auc: 0.5625 - loss: 1.3691 - val_auc: 0.7881 - val_loss: 0.5517 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - auc: 0.5916 - loss: 1.2526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 791ms/step - auc: 0.5923 - loss: 1.2498 - val_auc: 0.8784 - val_loss: 0.4572 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - auc: 0.6230 - loss: 1.1278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 754ms/step - auc: 0.6245 - loss: 1.1260 - val_auc: 0.9285 - val_loss: 0.3896 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799ms/step - auc: 0.7374 - loss: 0.9658"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 895ms/step - auc: 0.7362 - loss: 0.9660 - val_auc: 0.9561 - val_loss: 0.3417 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682ms/step - auc: 0.7184 - loss: 0.9134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 764ms/step - auc: 0.7195 - loss: 0.9125 - val_auc: 0.9644 - val_loss: 0.3126 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - auc: 0.7562 - loss: 0.8678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 784ms/step - auc: 0.7576 - loss: 0.8666 - val_auc: 0.9703 - val_loss: 0.2894 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - auc: 0.8031 - loss: 0.7507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 744ms/step - auc: 0.8039 - loss: 0.7503 - val_auc: 0.9746 - val_loss: 0.2693 - learning_rate: 1.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - auc: 0.8614 - loss: 0.6786"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 747ms/step - auc: 0.8612 - loss: 0.6793 - val_auc: 0.9788 - val_loss: 0.2506 - learning_rate: 1.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - auc: 0.8463 - loss: 0.6523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 764ms/step - auc: 0.8469 - loss: 0.6532 - val_auc: 0.9790 - val_loss: 0.2381 - learning_rate: 1.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - auc: 0.8778 - loss: 0.6291"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 749ms/step - auc: 0.8782 - loss: 0.6280 - val_auc: 0.9793 - val_loss: 0.2259 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 830ms/step - auc: 0.8876 - loss: 0.5845 - val_auc: 0.9783 - val_loss: 0.2170 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 680ms/step - auc: 0.9130 - loss: 0.5247 - val_auc: 0.9783 - val_loss: 0.2118 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 677ms/step - auc: 0.9318 - loss: 0.4632 - val_auc: 0.9773 - val_loss: 0.2103 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 695ms/step - auc: 0.9460 - loss: 0.4770 - val_auc: 0.9778 - val_loss: 0.2070 - learning_rate: 5.0000e-06\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 723ms/step - auc: 0.9609 - loss: 0.4618 - val_auc: 0.9792 - val_loss: 0.2026 - learning_rate: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 임계값 최적화"
      ],
      "metadata": {
        "id": "jDqz2Owdi6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ✅ 경로 설정\n",
        "val_dir = '/content/gdrive/MyDrive/dataset/cnn/val'\n",
        "model_stage1_path = '/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5'\n",
        "model_stage2_path = '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5'\n",
        "# ✅ 모델 불러오기\n",
        "model_1 = load_model(model_stage1_path)\n",
        "model_2 = load_model(model_stage2_path)\n",
        "\n",
        "# ✅ 검증 데이터 로딩\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 검증 데이터 제너레이터\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ✅ 클래스 매핑 정보 출력 (검증 데이터 기준)\n",
        "label_map = val_gen.class_indices\n",
        "inv_map = {v: k for k, v in label_map.items()}\n",
        "print(\"\\n✅ 클래스 매핑 (검증 데이터셋의 실제 클래스 인덱스):\", inv_map)\n",
        "\n",
        "# --- 임계값 최적화: 검증 데이터 사용 ---\n",
        "\n",
        "# ✅ 전체 검증 이미지 및 라벨 수집\n",
        "print(\"\\n검증 데이터 수집 중...\")\n",
        "x_val_all, y_val_all = [], []\n",
        "for i in range(len(val_gen)):\n",
        "    x_batch, y_batch = val_gen[i]\n",
        "    x_val_all.extend(x_batch)\n",
        "    y_val_all.extend(y_batch)\n",
        "\n",
        "x_val_all = np.array(x_val_all)\n",
        "y_val_all = np.array(y_val_all)\n",
        "y_val_true = np.argmax(y_val_all, axis=1) # One-hot encoded y_val_all을 단일 클래스 인덱스로 변환\n",
        "print(f\"총 검증 이미지 수: {len(x_val_all)}\")\n",
        "\n",
        "\n",
        "# ✅ Stage 1 예측 확률 (검증 데이터에 대해)\n",
        "print(\"\\nStage 1 예측 수행 중 (검증 데이터)...\")\n",
        "\n",
        "stage1_val_preds = model_1.predict(x_val_all, verbose=1)\n",
        "\n",
        "\n",
        "# ✅ 임계값 최적화 (proper recall ≥ 0.85 조건하에 improper recall 최대화)\n",
        "best_threshold = None\n",
        "best_improper_recall = -1\n",
        "best_val_preds_for_threshold = None # 최적 임계값에서의 검증 데이터 예측 결과 저장\n",
        "\n",
        "thresholds = np.arange(0.01, 0.5, 0.01) # 0.01부터 0.49까지 0.01 간격으로\n",
        "RECALL_MIN_PROPER = 0.85\n",
        "\n",
        "print(\"\\n🔍 Threshold 탐색 시작 (proper recall ≥ 0.85 조건 하에서 improper recall 최대화 - 검증 데이터 사용)\")\n",
        "\n",
        "for t in thresholds:\n",
        "    # Stage 1 예측을 이진화: t보다 크면 1_kickboard, 아니면 0_no_kickboard\n",
        "    stage1_val_binary = (stage1_val_preds > t).astype(int).flatten()\n",
        "\n",
        "    # Stage 1에서 '1' (has_kickboard)으로 분류된 이미지의 인덱스\n",
        "    stage2_val_indices = np.where(stage1_val_binary == 1)[0]\n",
        "    x_val_stage2 = x_val_all[stage2_val_indices]\n",
        "\n",
        "    # 최종 예측 결과 배열 초기화: 기본값은 Stage 1에서 0(no_kickboard)으로 분류된 'noise' (최종 클래스 인덱스: 1)\n",
        "    final_val_preds = np.full_like(stage1_val_binary, fill_value=1)\n",
        "\n",
        "    # Stage 2로 넘어갈 이미지가 있을 경우 Stage 2 모델 예측 수행\n",
        "    if len(x_val_stage2) > 0:\n",
        "        stage2_val_preds = model_2.predict(x_val_stage2, verbose=0)\n",
        "        # Stage 2는 0:improper, 1:proper 입니다.\n",
        "        stage2_val_classes = np.argmax(stage2_val_preds, axis=1) # Stage 2의 예측 클래스 (0 또는 1)\n",
        "\n",
        "        # Stage 2 예측을 최종 3개 클래스 (0:improper, 1:noise, 2:proper)에 매핑\n",
        "        # Stage 2가 0(improper)으로 예측하면 최종 0(improper)\n",
        "        # Stage 2가 1(proper)으로 예측하면 최종 2(proper)\n",
        "        final_val_preds[stage2_val_indices] = np.where(stage2_val_classes == 0, 0, 2)\n",
        "    # else 블록은 위에 final_val_preds 초기화로 이미 처리됨: Stage 2로 넘어갈 이미지가 없으면 모두 noise(1)\n",
        "\n",
        "    # 분류 리포트 생성 및 재현율 추출\n",
        "    report = classification_report(y_val_true, final_val_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    # 'proper'와 'improper' 클래스에 해당하는 재현율 추출\n",
        "    # inv_map (0: improper, 1: noise, 2: proper)에 따라\n",
        "    # proper는 '2', improper는 '0'\n",
        "    proper_recall = report.get('2', {}).get('recall', 0.0) # proper (클래스 2)의 recall\n",
        "    improper_recall = report.get('0', {}).get('recall', 0.0) # improper (클래스 0)의 recall\n",
        "\n",
        "    if proper_recall >= RECALL_MIN_PROPER:\n",
        "        print(f\" - threshold {t:.2f}: proper recall = {proper_recall:.4f}, improper recall = {improper_recall:.4f}\")\n",
        "        if improper_recall > best_improper_recall:\n",
        "            best_improper_recall = improper_recall\n",
        "            best_threshold = t\n",
        "            best_val_preds_for_threshold = final_val_preds.copy()\n",
        "\n",
        "# ✅ 최적 임계값 결과 출력 (검증 데이터 기준)\n",
        "print(\"\\n--- 임계값 최적화 결과 ---\")\n",
        "if best_threshold is not None:\n",
        "    print(f\"\\n✅ 최적 threshold (검증 데이터 기준): {best_threshold:.2f} (improper recall = {best_improper_recall:.4f}, proper recall ≥ {RECALL_MIN_PROPER:.2f})\")\n",
        "    print(\"\\n✅ Classification Report (최적 임계값 적용된 검증 데이터 결과)\")\n",
        "    print(classification_report(y_val_true, best_val_preds_for_threshold, target_names=['improper', 'noise', 'proper'], zero_division=0))\n",
        "    print(\"\\n✅ Confusion Matrix (최적 임계값 적용된 검증 데이터 결과)\")\n",
        "    print(confusion_matrix(y_val_true, best_val_preds_for_threshold))\n",
        "\n",
        "    # AUC 계산\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    y_val_true_one_hot = to_categorical(y_val_true, num_classes=3)\n",
        "    best_val_preds_for_threshold_one_hot = to_categorical(best_val_preds_for_threshold, num_classes=3)\n",
        "    auc = roc_auc_score(y_val_true_one_hot, best_val_preds_for_threshold_one_hot, multi_class='ovr')\n",
        "    print(f\"\\n✅ AUC (검증 데이터, macro): {auc:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\n⚠️ proper recall ≥ {RECALL_MIN_PROPER:.2f}를 만족하는 threshold가 검증 데이터에서 없습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL6aFTbpcrp_",
        "outputId": "c0990c9c-c97d-40bc-96fe-9ae09dbb2566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 109 images belonging to 3 classes.\n",
            "\n",
            "✅ 클래스 매핑 (검증 데이터셋의 실제 클래스 인덱스): {0: 'improper', 1: 'noise', 2: 'proper'}\n",
            "\n",
            "검증 데이터 수집 중...\n",
            "총 검증 이미지 수: 109\n",
            "\n",
            "Stage 1 예측 수행 중 (검증 데이터)...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 991ms/step\n",
            "\n",
            "🔍 Threshold 탐색 시작 (proper recall ≥ 0.85 조건 하에서 improper recall 최대화 - 검증 데이터 사용)\n",
            " - threshold 0.01: proper recall = 1.0000, improper recall = 0.7419\n",
            " - threshold 0.02: proper recall = 1.0000, improper recall = 0.7419\n",
            " - threshold 0.03: proper recall = 1.0000, improper recall = 0.7419\n",
            " - threshold 0.04: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.05: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.06: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.07: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.08: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.09: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.10: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.11: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.12: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.13: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.14: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.15: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.16: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.17: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.18: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.19: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.20: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.21: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.22: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.23: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.24: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.25: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.26: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.27: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.28: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.29: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.30: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.31: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.32: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.33: proper recall = 0.9683, improper recall = 0.6774\n",
            " - threshold 0.34: proper recall = 0.9524, improper recall = 0.6774\n",
            " - threshold 0.35: proper recall = 0.9365, improper recall = 0.6774\n",
            " - threshold 0.36: proper recall = 0.9365, improper recall = 0.6774\n",
            " - threshold 0.37: proper recall = 0.9206, improper recall = 0.6774\n",
            " - threshold 0.38: proper recall = 0.9206, improper recall = 0.6774\n",
            " - threshold 0.39: proper recall = 0.9206, improper recall = 0.6774\n",
            " - threshold 0.40: proper recall = 0.9048, improper recall = 0.6774\n",
            " - threshold 0.41: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.42: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.43: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.44: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.45: proper recall = 0.8889, improper recall = 0.6452\n",
            " - threshold 0.46: proper recall = 0.8889, improper recall = 0.6452\n",
            " - threshold 0.47: proper recall = 0.8889, improper recall = 0.6129\n",
            " - threshold 0.48: proper recall = 0.8889, improper recall = 0.6129\n",
            " - threshold 0.49: proper recall = 0.8889, improper recall = 0.6129\n",
            "\n",
            "--- 임계값 최적화 결과 ---\n",
            "\n",
            "✅ 최적 threshold (검증 데이터 기준): 0.01 (improper recall = 0.7419, proper recall ≥ 0.85)\n",
            "\n",
            "✅ Classification Report (최적 임계값 적용된 검증 데이터 결과)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    improper       1.00      0.74      0.85        31\n",
            "       noise       1.00      1.00      1.00        15\n",
            "      proper       0.89      1.00      0.94        63\n",
            "\n",
            "    accuracy                           0.93       109\n",
            "   macro avg       0.96      0.91      0.93       109\n",
            "weighted avg       0.93      0.93      0.92       109\n",
            "\n",
            "\n",
            "✅ Confusion Matrix (최적 임계값 적용된 검증 데이터 결과)\n",
            "[[23  0  8]\n",
            " [ 0 15  0]\n",
            " [ 0  0 63]]\n",
            "\n",
            "✅ AUC (검증 데이터, macro): 0.9280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 시각화"
      ],
      "metadata": {
        "id": "NZwHKx1BkIGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ✅ 클래스 이름\n",
        "class_names = ['improper', 'noise', 'proper']\n",
        "\n",
        "# ✅ 혼동행렬 정의 (직접 입력한 경우)\n",
        "cm = np.array([[23 ,0,  8],\n",
        " [ 0, 15,  0],\n",
        " [ 0,  0, 63]])\n",
        "\n",
        "# ✅ 시각화\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "WFiBPZMDkKAM",
        "outputId": "c855df47-e1a3-4b9d-cc5f-71faaa54c17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAHqCAYAAAAj28XgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUodJREFUeJzt3XdYFNf6B/DvgrAgSBUpUYqiCCr2ghixoKgximLsisaWBEtEjdfEAqgh19h7jd0YjVGjSexRo2LBXrGhmEhRFBAVRDi/P7zsLyuou7iws7vfz33meeTMzJl3uJv19T3nzMiEEAJEREREOsBI2wEQERERqYqJCxEREekMJi5ERESkM5i4EBERkc5g4kJEREQ6g4kLERER6QwmLkRERKQzmLgQERGRzmDiQkRERDqDiQuRhNy4cQOtW7eGtbU1ZDIZtm3bptH+79y5A5lMhlWrVmm0X13WrFkzNGvWTNthEJGKmLgQvebWrVsYMmQIKlasCDMzM1hZWcHf3x9z5szB8+fPi/XaoaGhuHjxIqZOnYq1a9eiXr16xXq9ktSvXz/IZDJYWVkV+nu8ceMGZDIZZDIZpk+frnb/9+/fR0REBM6dO6eBaIlIqkppOwAiKfntt9/wySefQC6Xo2/fvqhevTpevHiBI0eOYMyYMbh8+TKWLl1aLNd+/vw5YmJi8M0332Do0KHFcg03Nzc8f/4cJiYmxdL/u5QqVQrPnj3Djh070LVrV6V969evh5mZGbKysorU9/379xEZGQl3d3fUqlVL5fP27NlTpOsRkXYwcSH6n/j4eHTv3h1ubm44cOAAnJ2dFfvCwsJw8+ZN/Pbbb8V2/QcPHgAAbGxsiu0aMpkMZmZmxdb/u8jlcvj7++PHH38skLhs2LABH330EbZs2VIisTx79gylS5eGqalpiVyPiDSDQ0VE/zNt2jRkZmZixYoVSklLPk9PT4wYMULx88uXLzF58mRUqlQJcrkc7u7u+Prrr5Gdna10nru7O9q3b48jR46gQYMGMDMzQ8WKFbFmzRrFMREREXBzcwMAjBkzBjKZDO7u7gBeDbHk//nfIiIiIJPJlNr27t2LJk2awMbGBpaWlvDy8sLXX3+t2P+mOS4HDhzAhx9+CAsLC9jY2KBjx464evVqode7efMm+vXrBxsbG1hbW6N///549uzZm3+xr+nZsyf++OMPpKWlKdpOnTqFGzduoGfPngWOf/ToEUaPHo0aNWrA0tISVlZWaNu2Lc6fP6845uDBg6hfvz4AoH///oohp/z7bNasGapXr47Tp0+jadOmKF26tOL38vocl9DQUJiZmRW4/6CgINja2uL+/fsq3ysRaR4TF6L/2bFjBypWrIjGjRurdPzAgQMxceJE1KlTB7NmzUJAQACio6PRvXv3AsfevHkTXbp0QatWrTBjxgzY2tqiX79+uHz5MgCgc+fOmDVrFgCgR48eWLt2LWbPnq1W/JcvX0b79u2RnZ2NqKgozJgxAx06dMDRo0ffet6+ffsQFBSElJQUREREIDw8HMeOHYO/vz/u3LlT4PiuXbviyZMniI6ORteuXbFq1SpERkaqHGfnzp0hk8nwyy+/KNo2bNiAqlWrok6dOgWOv337NrZt24b27dtj5syZGDNmDC5evIiAgABFEuHt7Y2oqCgAwODBg7F27VqsXbsWTZs2VfSTmpqKtm3bolatWpg9ezaaN29eaHxz5syBg4MDQkNDkZubCwBYsmQJ9uzZg3nz5sHFxUXleyWiYiCISKSnpwsAomPHjiodf+7cOQFADBw4UKl99OjRAoA4cOCAos3NzU0AEIcPH1a0paSkCLlcLkaNGqVoi4+PFwDE999/r9RnaGiocHNzKxDDpEmTxL//E541a5YAIB48ePDGuPOvsXLlSkVbrVq1RLly5URqaqqi7fz588LIyEj07du3wPU+/fRTpT47deok7O3t33jNf9+HhYWFEEKILl26iJYtWwohhMjNzRVOTk4iMjKy0N9BVlaWyM3NLXAfcrlcREVFKdpOnTpV4N7yBQQECABi8eLFhe4LCAhQatu9e7cAIKZMmSJu374tLC0tRXBw8DvvkYiKHysuRAAyMjIAAGXKlFHp+N9//x0AEB4ertQ+atQoACgwF8bHxwcffvih4mcHBwd4eXnh9u3bRY75dflzY7Zv3468vDyVzklMTMS5c+fQr18/2NnZKdp9fX3RqlUrxX3+22effab084cffojU1FTF71AVPXv2xMGDB5GUlIQDBw4gKSmp0GEi4NW8GCOjV19Vubm5SE1NVQyDnTlzRuVryuVy9O/fX6VjW7dujSFDhiAqKgqdO3eGmZkZlixZovK1iKj4MHEhAmBlZQUAePLkiUrH3717F0ZGRvD09FRqd3Jygo2NDe7evavU7urqWqAPW1tbPH78uIgRF9StWzf4+/tj4MCBcHR0RPfu3bFp06a3JjH5cXp5eRXY5+3tjYcPH+Lp06dK7a/fi62tLQCodS/t2rVDmTJl8NNPP2H9+vWoX79+gd9lvry8PMyaNQuVK1eGXC5H2bJl4eDggAsXLiA9PV3la37wwQdqTcSdPn067OzscO7cOcydOxflypVT+VwiKj5MXIjwKnFxcXHBpUuX1Drv9cmxb2JsbFxouxCiyNfIn3+Rz9zcHIcPH8a+ffvQp08fXLhwAd26dUOrVq0KHPs+3ude8snlcnTu3BmrV6/G1q1b31htAYBvv/0W4eHhaNq0KdatW4fdu3dj7969qFatmsqVJeDV70cdZ8+eRUpKCgDg4sWLap1LRMWHiQvR/7Rv3x63bt1CTEzMO491c3NDXl4ebty4odSenJyMtLQ0xQohTbC1tVVagZPv9aoOABgZGaFly5aYOXMmrly5gqlTp+LAgQP4888/C+07P864uLgC+65du4ayZcvCwsLi/W7gDXr27ImzZ8/iyZMnhU5ozvfzzz+jefPmWLFiBbp3747WrVsjMDCwwO9E1SRSFU+fPkX//v3h4+ODwYMHY9q0aTh16pTG+ieiomPiQvQ/X331FSwsLDBw4EAkJycX2H/r1i3MmTMHwKuhDgAFVv7MnDkTAPDRRx9pLK5KlSohPT0dFy5cULQlJiZi69atSsc9evSowLn5D2J7fYl2PmdnZ9SqVQurV69WSgQuXbqEPXv2KO6zODRv3hyTJ0/G/Pnz4eTk9MbjjI2NC1RzNm/ejH/++UepLT/BKizJU9fYsWORkJCA1atXY+bMmXB3d0doaOgbf49EVHL4ADqi/6lUqRI2bNiAbt26wdvbW+nJuceOHcPmzZvRr18/AEDNmjURGhqKpUuXIi0tDQEBATh58iRWr16N4ODgNy61LYru3btj7Nix6NSpE4YPH45nz55h0aJFqFKlitLk1KioKBw+fBgfffQR3NzckJKSgoULF6J8+fJo0qTJG/v//vvv0bZtW/j5+WHAgAF4/vw55s2bB2tra0RERGjsPl5nZGSE8ePHv/O49u3bIyoqCv3790fjxo1x8eJFrF+/HhUrVlQ6rlKlSrCxscHixYtRpkwZWFhYoGHDhvDw8FArrgMHDmDhwoWYNGmSYnn2ypUr0axZM0yYMAHTpk1Tqz8i0jAtr2oikpzr16+LQYMGCXd3d2FqairKlCkj/P39xbx580RWVpbiuJycHBEZGSk8PDyEiYmJqFChghg3bpzSMUK8Wg790UcfFbjO68tw37QcWggh9uzZI6pXry5MTU2Fl5eXWLduXYHl0Pv37xcdO3YULi4uwtTUVLi4uIgePXqI69evF7jG60uG9+3bJ/z9/YW5ubmwsrISH3/8sbhy5YrSMfnXe3259cqVKwUAER8f/8bfqRDKy6Hf5E3LoUeNGiWcnZ2Fubm58Pf3FzExMYUuY96+fbvw8fERpUqVUrrPgIAAUa1atUKv+e9+MjIyhJubm6hTp47IyclROm7kyJHCyMhIxMTEvPUeiKh4yYRQY0YdERERkRZxjgsRERHpDCYuREREpDOYuBAREZHOYOJCREREOoOJCxEREekMJi5ERESkM5i4EBERkc7Qyyfnrom9p+0QSMd0rVVB2yGQDklMy9J2CKRjPMqalch1zGsP1Wh/z8/O12h/msCKCxEREekMvay4EBERGSSZ/tcjmLgQERHpC5lM2xEUO/1PzYiIiEhvsOJCRESkLwxgqEj/75CIiIj0BisuRERE+sIA5rgwcSEiItIXHCoiIiIikg5WXIiIiPQFh4qIiIhIZ3CoiIiIiEg6WHEhIiLSFwYwVMSKCxEREekMJi5ERET6Qmak2U1N//zzD3r37g17e3uYm5ujRo0aiI2NVewXQmDixIlwdnaGubk5AgMDcePGDbWuwcSFiIhIX8hkmt3U8PjxY/j7+8PExAR//PEHrly5ghkzZsDW1lZxzLRp0zB37lwsXrwYJ06cgIWFBYKCgpCVlaXydTjHhYiIiN7bf//7X1SoUAErV65UtHl4eCj+LITA7NmzMX78eHTs2BEAsGbNGjg6OmLbtm3o3r27StdhxYWIiEhfaHGo6Ndff0W9evXwySefoFy5cqhduzaWLVum2B8fH4+kpCQEBgYq2qytrdGwYUPExMSofB0mLkRERPpCw0NF2dnZyMjIUNqys7MLvfTt27exaNEiVK5cGbt378bnn3+O4cOHY/Xq1QCApKQkAICjo6PSeY6Ojop9qmDiQkRERIWKjo6GtbW10hYdHV3osXl5eahTpw6+/fZb1K5dG4MHD8agQYOwePFijcbExIWIiEhfaHioaNy4cUhPT1faxo0bV+ilnZ2d4ePjo9Tm7e2NhIQEAICTkxMAIDk5WemY5ORkxT5VMHEhIiLSFxpOXORyOaysrJQ2uVxe6KX9/f0RFxen1Hb9+nW4ubkBeDVR18nJCfv371fsz8jIwIkTJ+Dn56fyLXJVEREREb23kSNHonHjxvj222/RtWtXnDx5EkuXLsXSpUsBADKZDF9++SWmTJmCypUrw8PDAxMmTICLiwuCg4NVvg4TFyIiIn1hpL1H/tevXx9bt27FuHHjEBUVBQ8PD8yePRu9evVSHPPVV1/h6dOnGDx4MNLS0tCkSRPs2rULZmZmKl9HJoQQxXED2rQm9p62QyAd07VWBW2HQDokMU31h2URAYBHWdX/Yn4f5s0na7S/539O0Gh/msCKCxERkb4owmP6dQ0TFyIiIn3Bt0MTERERSQcrLkRERPqCQ0VERESkMzhURERERCQdrLgQERHpCwMYKtL/OyQiIiK9wYoLERGRvjCAOS5MXIiIiPQFh4qIiIiIpIMVFyIiIn1hAENFWq+4vHz5EmvWrEFycrK2QyEiItJtMiPNbhKk9ahKlSqFzz77DFlZfNsqERERvZ3WExcAaNCgAc6dO6ftMIiIiHSbTKbZTYIkMcfliy++QHh4OO7du4e6devCwsJCab+vr6+WIiMiItIhEh3e0SRJJC7du3cHAAwfPlzRJpPJIISATCZDbm6utkIjIiIiCZFE4hIfH6/tEIiIiHQfKy4lw83NTdshEBERkQ6QTGq2du1a+Pv7w8XFBXfv3gUAzJ49G9u3b9dyZERERDrCACbnSiJxWbRoEcLDw9GuXTukpaUp5rTY2Nhg9uzZ2g2OiIhIV/A5LiVj3rx5WLZsGb755hsYGxsr2uvVq4eLFy9qMTIiIiKSEknMcYmPj0ft2rULtMvlcjx9+lQLEREREekgiQ7vaJIkKi4eHh6FPoBu165d8Pb2LvmAiIiIdJEBDBVJouISHh6OsLAwZGVlQQiBkydP4scff0R0dDSWL1+u7fCIiIhIIiSRuAwcOBDm5uYYP348nj17hp49e8LFxQVz5sxRPJyOiIiI3sEAhookkbgAQK9evdCrVy88e/YMmZmZKFeunLZDIiIi0ikyJi4lKyUlBXFxcQBe/fIdHBy0HBERERFJiSRm3jx58gR9+vSBi4sLAgICEBAQABcXF/Tu3Rvp6enaDo+IiEgnyGQyjW5SJInEZeDAgThx4gR+++03pKWlIS0tDTt37kRsbCyGDBmi7fCIiIhIIiQxVLRz507s3r0bTZo0UbQFBQVh2bJlaNOmjRYjIyIi0iHSLJJolCQSF3t7e1hbWxdot7a2hq2trRYiIiIi0j1SHd7RJEkMFY0fPx7h4eFISkpStCUlJWHMmDGYMGGCFiMjIiIiKZFExWXRokW4efMmXF1d4erqCgBISEiAXC7HgwcPsGTJEsWxZ86c0VaYREREkmYIFRdJJC7BwcHaDoGIiEjnMXEpIZMmTdJ2CERERKQDJJG45Dt9+jSuXr0KAKhWrVqhb4ymtzu6fQPiYo8g9f49lDKVo3xlH7ToPgj2LhUUx/y+YhbiL51B5uNUmJqZ44PKPmjRYxDKurhqMXKSko0b1mP1yhV4+PABqnhVxX++noAavr7aDoskKDc3F+tWLMKBPb/hcWoq7Ms6ILBdB/TsN9gg/vUvNYbwO5dE4pKSkoLu3bvj4MGDsLGxAQCkpaWhefPm2LhxI5+gq4aEaxdQN7AjXCp5IS83F39uWoEN343FkGkrYGpmDgBw8qiM6o1bwqpsOTzPfIK/flmDH78bi7DZ62BkZKzlOyBt2/XH75g+LRrjJ0WiRo2aWL92NT4fMgDbd+6Cvb29tsMjidm8biV+27YZo8ZPhptHJdy4dgUzp06EhaUlgj/ppe3wSA9JYlXRsGHD8OTJE1y+fBmPHj3Co0ePcOnSJWRkZGD48OHaDk+n9Bj7HWoGBMGhvDsc3Srh4yFfISM1BUnxNxTH1GnRHq7evrBxcIKzR2UEfNIfGakPkP4gWYuRk1SsXb0Snbt0RXCnEFTy9MT4SZEwMzPDtl+2aDs0kqArl86h0YfN0LBxUzg5f4APm7dCnQZ+iLtySduhGSaZhjcJkkTismvXLixcuBDe3t6KNh8fHyxYsAB//PGHFiPTfdnPngIAzCzLFLr/RdZzXDi0CzYOTrCyZ2XL0OW8eIGrVy6jkV9jRZuRkREaNWqMC+fPajEykiqf6rVwLvYk/k64AwC4fSMOly+cRf1GTd5+IhULQ3jkvySGivLy8mBiYlKg3cTEBHl5eVqISD+IvDzsXbsQ5atUQ7kKHkr7Yvdux4EflyEnOwv2zhXQc9w0GJcq+P8BGZbHaY+Rm5tbYEjI3t4e8fG3tRQVSVnXPp/i2bNMDOoZDCMjY+Tl5SJ08DC0CPpI26GRnpJE4tKiRQuMGDECP/74I1xcXAAA//zzD0aOHImWLVu+9dzs7GxkZ2crteW8yIaJqbzY4tUVu1bNxYO/76DvxNkF9lX3b4mKNeoi8/EjHP99M36ZOxmhk+aglKlpyQdKRDrr8IHdOLDnd4yNiIabhydu3biGJXO+h31ZB7Rq10Hb4RkcqVZJNEkSQ0Xz589HRkYG3N3dUalSJVSqVAkeHh7IyMjAvHnz3npudHQ0rK2tlbadqxaUUOTStWvVPNw4ewK9v5le6BCQWWlL2DmVh6u3L0JGTERq4j3ExR7RQqQkJbY2tjA2NkZqaqpSe2pqKsqWLaulqEjKli+Yha69P0WzwLbwqFQZgW0+RqduvfHT2hXaDs0gcaiohFSoUAFnzpzBvn37cO3aNQCAt7c3AgMD33nuuHHjEB4ertS2+VJKscSpC4QQ2L16PuJij6DP+BmwKees0jlCCLzMySmBCEnKTExN4e1TDSeOx6BFy1f//eXl5eHEiRh079Fby9GRFGVnZcHISPnfwEZGxhCCw/xUPLSeuOTk5MDc3Bznzp1Dq1at0KpVK7XOl8vlkMuVh4VMTNM1GaJO2bVqLi4fO4BPwqNgalYamWmPAADy0hYwMZXjccp9XIk5iIq+9VC6jDWePHqIYzs2wsTUFJ61Gmg5epKCPqH9MeHrsahWrTqq1/DFurWr8fz5cwR36qzt0EiCGvoHYOPqZXBwdIKbRyXcun4NW39ai9YfddR2aAZJqlUSTdJ64mJiYgJXV1fk5uZqOxS9cGbfDgDAuimjlNrbDx6DmgFBKGViintxl3Bq1y94/jQTFta2cK1aA6GT5sLCmm/iJqBN23Z4/OgRFs6fi4cPH8CrqjcWLlkOew4VUSG+GPkfrFm2AAumf4u0x49gX9YBbTt2Qa/+Q7QdmmHS/7wFMiGE0HYQK1aswC+//IK1a9fCzs7uvftbE3tPA1GRIelaq8K7DyL6n8S0LG2HQDrGo6xZiVzHPvRHjfaXurqHRvvTBK1XXIBXk3Nv3rwJFxcXuLm5wcLCQmk/3whNRET0bhwqKiF8OzQRERGpQhKJC98OTURE9P5YcSlhsbGxirdD+/j4oG7dulqOiIiISHcwcSkhf//9N3r06IGjR48qvR26cePG2LhxI8qXL6/dAImIiEgSJPHk3IEDByInJwdXr15VvB366tWryMvLw8CBA7UdHhERkW7g26FLxqFDh7Bo0SJ4eXkp2ry8vDBv3jwcPnxYi5ERERHpDm0+8j8iIqLA+VWrVlXsz8rKQlhYGOzt7WFpaYmQkBAkJyerfY+SSFwqVKiAnEIeN5+bm6t46SIRERFJW7Vq1ZCYmKjYjhz5/3fgjRw5Ejt27MDmzZtx6NAh3L9/H507q/9EbknMcfn+++8xbNgwLFiwAPXq1QPwaqLuiBEjMH36dC1HR0REpBu0PTm3VKlScHJyKtCenp6OFStWYMOGDWjRogUAYOXKlfD29sbx48fRqFEjla8hiYpLv379cO7cOTRs2FDx7qGGDRvizJkz+PTTT2FnZ6fYiIiIqHDafjv0jRs34OLigooVK6JXr15ISEgAAJw+fRo5OTlKL0+uWrUqXF1dERMTo9Y1JFFxmT17trZDICIiotdkZ2cjOztbqa2wlxsDQMOGDbFq1Sp4eXkhMTERkZGR+PDDD3Hp0iUkJSXB1NRUsXI4n6OjI5KSktSKSRKJS2hoqLZDICIi0nmaHiqKjo5GZGSkUtukSZMQERFR4Ni2bdsq/uzr64uGDRvCzc0NmzZtgrm5ucZikkTiki8lJQUpKSnIy8tTavf19dVSRERERIZr3LhxCA8PV2orrNpSGBsbG1SpUgU3b95Eq1at8OLFC6SlpSlVXZKTkwudE/M2kkhcTp8+jdDQUFy9ehWvv6xaJpMhNzdXS5ERERHpEA3PzX3TsJAqMjMzcevWLfTp0wd169aFiYkJ9u/fj5CQEABAXFwcEhIS4Ofnp1a/kkhcPv30U1SpUgUrVqyAo6Oj1mdFExER6SJt/v05evRofPzxx3Bzc8P9+/cxadIkGBsbo0ePHrC2tsaAAQMQHh4OOzs7WFlZYdiwYfDz81NrRREgkcTl9u3b2LJlCzw9PbUdChERERVB/ut7UlNT4eDggCZNmuD48eNwcHAAAMyaNQtGRkYICQlBdnY2goKCsHDhQrWvI4nEpWXLljh//jwTFyIiovegzYrLxo0b37rfzMwMCxYswIIFC97rOpJIXJYvX47Q0FBcunQJ1atXh4mJidL+Dh06aCkyIiIi3WEIUy0kkbjExMTg6NGj+OOPPwrs4+RcIiIiyieJJ+cOGzYMvXv3RmJiIvLy8pQ2Ji1EREQq4tuhS0ZqaipGjhwJR0dHbYdCREREEiaJxKVz5874888/tR0GERGRTtP2u4pKgiTmuFSpUgXjxo3DkSNHUKNGjQKTc4cPH66lyIiIiHSHVJMNTZJE4rJ8+XJYWlri0KFDOHTokNI+mUzGxIWIiIgASCRxiY+P13YIREREOo8Vl2IUHh6OyZMnw8LCosALnP5NJpNhxowZJRgZERGRbmLiUozOnj2LnJwcxZ/fxBD+TyAiIiLVaC1x+fcqIq4oIiIi0gAD+Le+JOa4EBER0fszhFEKSTzHhYiIiEgVrLgQERHpCVZciIiIiCSEFRciIiI9YQAFFyYuRERE+oJDRUREREQSwooLERGRnjCAggsTFyIiIn3BoSIiIiIiCWHFhYiISE8YQMGFiQsREZG+MDLS/8yFQ0VERESkM1hxISIi0hOGMFTEigsRERHpDFZciIiI9IQhLIdm4kJERKQnDCBv4VARERER6Q5WXIiIiPQEh4qIiIhIZxhC4sKhIiIiItIZrLgQERHpCQMouLDiQkRERLqDFRciIiI9YQhzXJi4EBER6QkDyFs4VERERES6gxUXIiIiPcGhIiIiItIZBpC3cKiIiIiIdAcrLkRERHqCQ0VERESkMwwgb+FQEREREekOVlyIiIj0hCEMFbHiQkRERDpDLysuXWtV0HYIpGMuJKRrOwTSIb6u1toOgahQBlBw0c/EhYiIyBBxqIiIiIhIQlhxISIi0hMGUHBh4kJERKQvOFREREREJCGsuBAREekJAyi4sOJCREREuoOJCxERkZ6QyWQa3d7Hd999B5lMhi+//FLRlpWVhbCwMNjb28PS0hIhISFITk5Wq18mLkRERHpCKonLqVOnsGTJEvj6+iq1jxw5Ejt27MDmzZtx6NAh3L9/H507d1arbyYuREREpDGZmZno1asXli1bBltbW0V7eno6VqxYgZkzZ6JFixaoW7cuVq5ciWPHjuH48eMq98/EhYiISE/IZJrdiiIsLAwfffQRAgMDldpPnz6NnJwcpfaqVavC1dUVMTExKvfPVUVERER6QtPPccnOzkZ2drZSm1wuh1wuL/T4jRs34syZMzh16lSBfUlJSTA1NYWNjY1Su6OjI5KSklSOiRUXIiIiKlR0dDSsra2Vtujo6EKPvXfvHkaMGIH169fDzMys2GJixYWIiEhPaPo5LuPGjUN4eLhS25uqLadPn0ZKSgrq1KmjaMvNzcXhw4cxf/587N69Gy9evEBaWppS1SU5ORlOTk4qx8TEhYiISE9oeqjobcNCr2vZsiUuXryo1Na/f39UrVoVY8eORYUKFWBiYoL9+/cjJCQEABAXF4eEhAT4+fmpHBMTFyIiInpvZcqUQfXq1ZXaLCwsYG9vr2gfMGAAwsPDYWdnBysrKwwbNgx+fn5o1KiRytdh4kJERKQnpP7I/1mzZsHIyAghISHIzs5GUFAQFi5cqFYfMiGEKKb4tCbrpbYjIF1zISFd2yGQDvF1tdZ2CKRjzEqoTNBynurLilWxf5jqQzglhRUXIiIiPWEk9ZKLBjBxISIi0hMGkLfwOS5ERESkO1hxISIi0hOaXg4tRUxciIiI9ISR/uctHCoiIiIi3cGKCxERkZ7gUBERERHpDAPIWzhURERERLqDFRciIiI9IYP+l1xYcSEiIiKdwYoLERGRnjCE5dBMXIiIiPSEIawq4lARERER6QyVKi4XLlxQuUNfX98iB0NERERFZwAFF9USl1q1akEmk0EIUej+/H0ymQy5ubkaDZCIiIhUY2QAmYtKiUt8fHxxx0FERET0TiolLm5ubsUdBxEREb0nAyi4FG1y7tq1a+Hv7w8XFxfcvXsXADB79mxs375do8ERERER/ZvaicuiRYsQHh6Odu3aIS0tTTGnxcbGBrNnz9Z0fERERKQimUym0U2K1E5c5s2bh2XLluGbb76BsbGxor1evXq4ePGiRoMjIiIi1clkmt2kSO3EJT4+HrVr1y7QLpfL8fTpU40ERURERFQYtRMXDw8PnDt3rkD7rl274O3trYmYiIiIqAiMZDKNblKk9iP/w8PDERYWhqysLAghcPLkSfz444+Ijo7G8uXLiyNGIiIiUoE0Uw3NUjtxGThwIMzNzTF+/Hg8e/YMPXv2hIuLC+bMmYPu3bsXR4xEREREAIr4ksVevXqhV69eePbsGTIzM1GuXDlNx0VERERqkupKIE0q8tuhU1JSEBcXB+DVL8rBwUFjQREREZH6jPQ/b1F/cu6TJ0/Qp08fuLi4ICAgAAEBAXBxcUHv3r2Rnp5eHDESERERAShC4jJw4ECcOHECv/32G9LS0pCWloadO3ciNjYWQ4YMKY4YiYiISAWG8AA6tYeKdu7cid27d6NJkyaKtqCgICxbtgxt2rTRaHBERERE/6Z24mJvbw9ra+sC7dbW1rC1tdVIUERERKQ+iRZJNErtoaLx48cjPDwcSUlJirakpCSMGTMGEyZM0GhwREREpDoOFf1P7dq1lW7gxo0bcHV1haurKwAgISEBcrkcDx484DwXIiIiKjYqJS7BwcHFHMb/y8rKgpmZWYldj4iISF8YwnJolRKXSZMmFWsQeXl5mDp1KhYvXozk5GRcv34dFStWxIQJE+Du7o4BAwYU6/WJiIj0gVSHdzRJ7TkuxWHKlClYtWoVpk2bBlNTU0V79erV+f4jIiIiUlA7ccnNzcX06dPRoEEDODk5wc7OTmkrijVr1mDp0qXo1asXjI2NFe01a9bEtWvXitQnERGRoZFpeJMitROXyMhIzJw5E926dUN6ejrCw8PRuXNnGBkZISIiokhB/PPPP/D09CzQnpeXh5ycnCL1SUREZGiMZDKNblKkduKyfv16LFu2DKNGjUKpUqXQo0cPLF++HBMnTsTx48eLFISPjw/++uuvAu0///wzateuXaQ+iYiISP+o/QC6pKQk1KhRAwBgaWmpeD9R+/bti/wcl4kTJyI0NBT//PMP8vLy8MsvvyAuLg5r1qzBzp07i9QnERGRoZFokUSj1K64lC9fHomJiQCASpUqYc+ePQCAU6dOQS6XFymIjh07YseOHdi3bx8sLCwwceJEXL16FTt27ECrVq2K1CcRERHpH7UrLp06dcL+/fvRsGFDDBs2DL1798aKFSuQkJCAkSNHFjmQDz/8EHv37i3y+URERIbOEJZDq524fPfdd4o/d+vWDW5ubjh27BgqV66Mjz/+uEhB3Lt3DzKZDOXLlwcAnDx5Ehs2bICPjw8GDx5cpD6JiIgMjQHkLe//HJdGjRohPDwcDRs2xLffflukPnr27Ik///wTwKs5NIGBgTh58iS++eYbREVFvW+IBGDjhvVo26oF6teugV7dP8HFCxe0HRJJxLWLZzBjUjiG9WqHPm0bIPbYQaX9S2ZEok/bBkrbtPHDtRMsSRa/Y6ikaOwBdImJiUWenHvp0iU0aNAAALBp0ybUqFEDx44dw/r167Fq1SpNhWiwdv3xO6ZPi8aQL8KwcfNWeHlVxedDBiA1NVXboZEEZGdlwbViZYR+MeaNx/jW88O89b8rtrCxU0owQpI6fsdIB5dDl5CcnBzFxN59+/ahQ4cOAICqVasqJgJT0a1dvRKdu3RFcKcQVPL0xPhJkTAzM8O2X7ZoOzSSgJr1G+OT0M9Rz7/5G48pZWICG7uyis2ijFUJRkhSx+8Y6ZDJNLtJkSQSl2rVqmHx4sX466+/sHfvXrRp0wYAcP/+fdjb22s5Ot2W8+IFrl65jEZ+jRVtRkZGaNSoMS6cP6vFyEiXXLtwBl90D8KYgV2wct53eJKRpu2QSCL4HUMlTe3JucXhv//9Lzp16oTvv/8eoaGhqFmzJgDg119/VQwhUdE8TnuM3NzcAgmgvb094uNvaykq0iW+df1Q3785HBxdkJz4NzavWoTpE77EpJkrYPSvV3SQYeJ3jLRwVdG/hIeHv3X/gwcPihxEs2bN8PDhQ2RkZMDW1lbRPnjwYJQuXfqt52ZnZyM7O1upTRjLi/xMGSJS5testeLPFTw84epRGaM+7YSrF06jWm3+w4KISpbKicvZs+8u+TVt2rTIgRgbGyslLQDg7u7+zvOio6MRGRmp1PbNhEkYPzGiyLHoE1sbWxgbGxeYJJeamoqyZctqKSrSZeWcP0AZKxskJ/7NxIX4HSMxkpj/UcxUTlzylytrSp06dbB//37Y2tqidu3aby1vnTlz5o37xo0bV6AaJIxZbclnYmoKb59qOHE8Bi1aBgJ49fLKEydi0L1Hby1HR7ro0YNkZD5Jh40d/1IifsdIDYeKilHHjh0VwznBwcFF7kcuLzgslPXyfSLTP31C+2PC12NRrVp1VK/hi3VrV+P58+cI7tRZ26GRBGQ9f4bk+38rfn6QfB93b12HRRkrWJaxwtb1y1Hfvzms7eyRcv9vbPxhPhxdyqNGnUZajJqkhN8xVJK0lrhMmjSp0D+T5rVp2w6PHz3Cwvlz8fDhA3hV9cbCJcthzzIuAYi/cRXfjv1c8fOGpbMBAE0CP0L/oWNxL/4G/tr3G549fQJbOwdUr9MQXfoOgYmpqZYiJqnhd4x0GOl/wQUyIYTQdhD5Tp8+jatXrwJ4tUS6du3aReqHFRdS14WEdG2HQDrE19Va2yGQjjEroTJB+K/XNNrfzA5VNdqfJkhiHk9KSgpatGiB+vXrY/jw4Rg+fDjq1q2Lli1bvtdqJSIiIioZixYtgq+vL6ysrGBlZQU/Pz/88ccfiv1ZWVkICwuDvb09LC0tERISguTkZLWvI4nEZdiwYXjy5AkuX76MR48e4dGjR7h06RIyMjIwfDjfiUJERKQKmUym0U0d5cuXx3fffYfTp08jNjYWLVq0QMeOHXH58mUAwMiRI7Fjxw5s3rwZhw4dwv3799G5s/rzoIo0VPTXX39hyZIluHXrFn7++Wd88MEHWLt2LTw8PNCkSRO1g7C2tsa+fftQv359pfaTJ0+idevWSEtLU6s/DhWRujhUROrgUBGpq6SGisbsjNNof9+393qv8+3s7PD999+jS5cucHBwwIYNG9ClSxcAwLVr1+Dt7Y2YmBg0aqT6ZH+1Ky5btmxBUFAQzM3NcfbsWcXD39LT04v8dui8vDyYmJgUaDcxMUFeXl6R+iQiIqL3k52djYyMDKXt9Ye+FiY3NxcbN27E06dP4efnh9OnTyMnJweBgYGKY6pWrQpXV1fExMSoFZPaicuUKVOwePFiLFu2TCnZ8Pf3f+vzVt6mRYsWGDFiBO7fv69o++effzBy5Ei0bNmySH0SEREZGk2/ZDE6OhrW1tZKW3R09Buvf/HiRVhaWkIul+Ozzz7D1q1b4ePjg6SkJJiamsLGxkbpeEdHRyQlJal1j2oXr+Li4gp9Qq61tbXaQzr55s+fjw4dOsDd3R0VKlQAACQkJKBGjRpYt25dkfokIiKi91PYQ17f9kodLy8vnDt3Dunp6fj5558RGhqKQ4cOaTQmtRMXJycn3Lx5s8Dj+I8cOYKKFSsWKYgKFSrgzJkz2L9/v2I5tLe3t1JJiYiIiN7OSMNPzi3sIa9vY2pqCk9PTwBA3bp1cerUKcyZMwfdunXDixcvkJaWplR1SU5OhpOTk1oxqZ24DBo0CCNGjMAPP/wAmUyG+/fvIyYmBqNHj8aECRPU7U7hwIEDOHDgAFJSUpCXl4ezZ89iw4YNAIAffvihyP0SEREZCkksFf6XvLw8ZGdno27dujAxMcH+/fsREhIC4NUITkJCAvz8/NTqU+3E5T//+Q/y8vLQsmVLPHv2DE2bNoVcLsfo0aMxbNgwdbsDAERGRiIqKgr16tWDs7OzQbxrgYiISJ+MGzcObdu2haurK548eYINGzbg4MGD2L17N6ytrTFgwACEh4fDzs4OVlZWGDZsGPz8/NRaUQQUIXGRyWT45ptvMGbMGNy8eROZmZnw8fGBpaWlul0pLF68GKtWrUKfPn2K3AcREZGh0+a/+1NSUtC3b18kJibC2toavr6+2L17N1q1agUAmDVrFoyMjBASEoLs7GwEBQVh4cKFal9HEo/8t7e3x8mTJ1GpUiWN9MfnuJC6+BwXUgef40LqKqnnuEzYdUOj/U1uU1mj/WmC2r/K5s2bv3Uo58CBA2oHMXDgQGzYsOG95sgQERGR/lM7calVq5bSzzk5OTh37hwuXbqE0NDQIgWRlZWFpUuXYt++ffD19S3wMLqZM2cWqV8iIiJDYghTRNVOXGbNmlVoe0REBDIzM4sUxIULFxQJ0aVLl5T2caIuERGRaowM4K9MjY269e7dGw0aNMD06dPVPvfPP//UVBhERESkxzSWuMTExMDMzExT3REREZGaNP0AOilSO3F5/RXUQggkJiYiNjaWk2uJiIioWKmduFhbKy8DNDIygpeXF6KiotC6dWuNBUZERETqMYCCi3qJS25uLvr3748aNWrA1ta2uGIiIiKiIjCEyblqvdbA2NgYrVu3LvJboImIiIjeh9rvY6pevTpu375dHLEQERHRe5Bp+H9SpHbiMmXKFIwePRo7d+5EYmIiMjIylDYiIiLSDiOZZjcpUnmOS1RUFEaNGoV27doBADp06KD0cDghBGQyGXJzczUfJRERERHUSFwiIyPx2Wef8WFxREREEiXVKokmqZy45L9EOiAgoNiCISIiInobtZZD871BRERE0mUIf0+rlbhUqVLlnb+UR48evVdAREREVDQcKnpNZGRkgSfnEhEREZUUtRKX7t27o1y5csUVCxEREb0HAxgpUj1xMYRxMyIiIl1mCG+HVvkBdPmrioiIiIi0ReWKS15eXnHGQURERO+Jk3OJiIhIZxjASJH67yoiIiIi0hZWXIiIiPSEkUTf6KxJrLgQERGRzmDFhYiISE8YwhwXJi5ERER6whBWFXGoiIiIiHQGKy5ERER6whCenMvEhYiISE8YQN7CoSIiIiLSHay4EBER6QkOFREREZHOMIC8hUNFREREpDtYcSEiItIThlCNMIR7JCIiIj3BigsREZGekBnAJBcmLkRERHpC/9MWDhURERGRDmHFhYiISE/wOS5ERESkM/Q/beFQEREREekQVlyIiIj0hAGMFLHiQkRERLqDFRciIiI9wee4EBERkc4whGEUQ7hHIiIi0hOsuBAREekJDhURERGRztD/tIVDRURERKRDWHEhIiLSExwqIjIQvq7W2g6BdIht/aHaDoF0zPOz80vkOoYwjGII90hERER6gokLERGRnpDJZBrd1BEdHY369eujTJkyKFeuHIKDgxEXF6d0TFZWFsLCwmBvbw9LS0uEhIQgOTlZreswcSEiIqL3dujQIYSFheH48ePYu3cvcnJy0Lp1azx9+lRxzMiRI7Fjxw5s3rwZhw4dwv3799G5c2e1riMTQghNB69tWS+1HQER6TPOcSF1ldQcl20XkjTaX7CvU5HPffDgAcqVK4dDhw6hadOmSE9Ph4ODAzZs2IAuXboAAK5duwZvb2/ExMSgUaNGKvXLigsREZGekMk0u2VnZyMjI0Npy87OVimW9PR0AICdnR0A4PTp08jJyUFgYKDimKpVq8LV1RUxMTEq3yMTFyIiIipUdHQ0rK2tlbbo6Oh3npeXl4cvv/wS/v7+qF69OgAgKSkJpqamsLGxUTrW0dERSUmqV4q4HJqIiEhPGGn42bnjxo1DeHi4UptcLn/neWFhYbh06RKOHDmi0XgAJi5ERER6Q9PPn5PL5SolKv82dOhQ7Ny5E4cPH0b58uUV7U5OTnjx4gXS0tKUqi7JyclwclJ9Lg2HioiIiOi9CSEwdOhQbN26FQcOHICHh4fS/rp168LExAT79+9XtMXFxSEhIQF+fn4qX4cVFyIiIj0h0+JrFsPCwrBhwwZs374dZcqUUcxbsba2hrm5OaytrTFgwACEh4fDzs4OVlZWGDZsGPz8/FReUQQwcSEiIiINWLRoEQCgWbNmSu0rV65Ev379AACzZs2CkZERQkJCkJ2djaCgICxcuFCt6/A5LkREauJzXEhdJfUcl98vp2i0v3bVymm0P01gxYWIiEhPaHpVkRRxci4RERHpDFZciIiI9ISml0NLERMXIiIiPWEIiQuHioiIiEhnsOJCRESkJ7T5HJeSwsSFiIhITxjpf97CoSIiIiLSHay4EBER6QlDGCpixYWIiIh0BisuREREesIQlkMzcSEiItITHCoiIiIikhBWXIiIiPSEISyHZuJCRESkJzhURERERCQhrLgQERHpCa4qIiIiIp1hAHkLh4qIiIhId7DiQkREpCeMDGCsiBUXIiIi0hmsuBAREekJ/a+3MHEhIiLSHwaQuXCoiIiIiHQGKy5ERER6whCenMvEhYiISE8YwKIiDhURERGR7mDFhYiISE8YQMGFFRciIiLSHay4EBER6QsDKLkwcSEiItIThrCqiENFREREpDNYcSEiItIThrAcmokLERGRnjCAvEX7Q0U5OTkoVaoULl26pO1QiIiISOK0XnExMTGBq6srcnNztR0KERGRbjOAkovWKy4A8M033+Drr7/Go0ePtB0KERGRzpJp+H9SpPWKCwDMnz8fN2/ehIuLC9zc3GBhYaG0/8yZM1qKjIiIiKREEolLcHCwtkMgIiLSeVxVVEImTZqk7RCIiIhIB0hijgsApKWlYfny5Rg3bpxirsuZM2fwzz//aDkyIiIi3SDT8CZFkqi4XLhwAYGBgbC2tsadO3cwaNAg2NnZ4ZdffkFCQgLWrFmj7RCJiIikT6rZhgZJouISHh6Ofv364caNGzAzM1O0t2vXDocPH9ZiZERERCQlkqi4nDp1CkuWLCnQ/sEHHyApKUkLEREREekeqS5h1iRJJC5yuRwZGRkF2q9fvw4HBwctRERERKR7DGFVkSSGijp06ICoqCjk5OQAAGQyGRISEjB27FiEhIRoOToiIiKSCkkkLjNmzEBmZibKlSuH58+fIyAgAJ6enihTpgymTp2q7fCIiIh0AlcVlRBra2vs3bsXR44cwYULF5CZmYk6deogMDBQ26ERERHpDqlmGxokicQlX5MmTdCkSRNth6GXNm5Yj9UrV+Dhwweo4lUV//l6Amr4+mo7LJIofl7obVwcrDFlREe09q+G0mYmuHXvIYZErMOZKwkAgG+GtMMnQXVQ3skWL3JycfZqAiLm78CpS3e1HDnpA0kMFQHA/v370b59e1SqVAmVKlVC+/btsW/fPm2HpRd2/fE7pk+LxpAvwrBx81Z4eVXF50MGIDU1VduhkQTx80JvY1PGHAdWhSPnZR6Chy5E7ZCp+M/MX/A445nimJt3UzDyv5tR75Nv0bL/TNy9/wg7Fg5FWVtLLUZuGAzhJYuSSFwWLlyINm3aoEyZMhgxYgRGjBgBKysrtGvXDgsWLNB2eDpv7eqV6NylK4I7haCSpyfGT4qEmZkZtv2yRduhkQTx80JvM6p/K/yd9BhDItYh9vJd3L2fiv3HryH+74eKY37aFYs/T8Thzj+puHo7CWNn/ALrMuaoXtlFi5GTvpDEUNG3336LWbNmYejQoYq24cOHw9/fH99++y3CwsK0GJ1uy3nxAlevXMaAQUMUbUZGRmjUqDEunD+rxchIivh5oXf5KKAG9h27ivXTPkWTupVxPyUNSzf9hZVbjxV6vEkpYwzo7I+0J89w8Tpf4VLcuBy6hKSlpaFNmzYF2lu3bo309HQtRKQ/Hqc9Rm5uLuzt7ZXa7e3t8fDhwzecRYaKnxd6F48PymLQJx/iZsIDdPhiAZZtPoIZX3VBr48bKh3X9sPqeHB0BtJOzMKw3s3R/rP5SE17qqWoDYchrCqSROLSoUMHbN26tUD79u3b0b59+7eem52djYyMDKUtOzu7uEIlIjJoRkYynLt2D5Pm78D5uL/xwy9HsXLrMQzqoryw4tCp62jYPRrN+83EnmNXsG7ap3DgHBe9dvjwYXz88cdwcXGBTCbDtm3blPYLITBx4kQ4OzvD3NwcgYGBuHHjhtrXkUTi4uPjg6lTp+Kjjz7ClClTMGXKFLRv3x5Tp05F9erVMXfuXMX2uujoaFhbWytt3/83Wgt3IU22NrYwNjYuMLEyNTUVZcuW1VJUJFX8vNC7JD3MwNXbyq9iuRafhApOtkptz7Je4Pa9hzh58Q4+j9yAl7l5CO3UuCRDNUxaLLk8ffoUNWvWfOPc1GnTpmHu3LlYvHgxTpw4AQsLCwQFBSErK0ut60hijsuKFStga2uLK1eu4MqVK4p2GxsbrFixQvGzTCbD8OHDlc4dN24cwsPDldqEsbx4A9YhJqam8PaphhPHY9Ci5avn4uTl5eHEiRh079Fby9GR1PDzQu8Sc+42qriVU2qr7FoOCYmP3nqekUwGuYkk/srRa9pcCdS2bVu0bdu20H1CCMyePRvjx49Hx44dAQBr1qyBo6Mjtm3bhu7du6t8HUl8iuLj44t8rlwuh1yunKhkvXzfiPRLn9D+mPD1WFSrVh3Va/hi3drVeP78OYI7ddZ2aCRB/LzQ28xbdwB/rhqFMZ+2xpa9Z1C/mjs+DfHH0Mk/AgBKm5li7MAg/HboIpIepsPexhJDujaFSzkb/LL3jJajJ22Jj49HUlKS0oNlra2t0bBhQ8TExOhe4vJvQggAr6orpBlt2rbD40ePsHD+XDx8+ABeVb2xcMly2LP0T4Xg54Xe5vSVBHQbtQxRwzrg68FtceefVIz5fgs2/hELAMjNy4OXuyN6f9wQ9jYWeJT+DLGX7yLw01kFhphI8zT9V2d2dnaBeaOFFQzeJSnp1f/3jo6OSu2Ojo6KfaqSTOKyZs0afP/994qJOlWqVMGYMWPQp08fLUemH3r06o0evVjqJ9Xw80Jv88dfl/DHX5cK3Zf94iW6j15ewhFRcYmOjkZkZKRS26RJkxAREaGdgCCRxGXmzJmYMGEChg4dCn9/fwDAkSNH8Nlnn+Hhw4cYOXKkliMkIiKSPk2PVRQ2j1TdagsAODk5AQCSk5Ph7OysaE9OTkatWrXU6ksSicu8efOwaNEi9O3bV9HWoUMHVKtWDREREUxciIiIVKHhzKUow0KF8fDwgJOTE/bv369IVDIyMnDixAl8/vnnavUlicQlMTERjRsXXCbXuHFjJCYmaiEiIiIiUkdmZiZu3ryp+Dk+Ph7nzp2DnZ0dXF1d8eWXX2LKlCmoXLkyPDw8MGHCBLi4uCA4OFit60jiOS6enp7YtGlTgfaffvoJlStX1kJEREREukebL1mMjY1F7dq1Ubt2bQBAeHg4ateujYkTJwIAvvrqKwwbNgyDBw9G/fr1kZmZiV27dsHMzEy9exT5y3i0aMuWLejWrRsCAwMVc1yOHj2K/fv3Y9OmTejUqZNa/XE5NBEVJ9v6Q999ENG/PD87v0SuczPluUb78yxnrtH+NEESFZeQkBCcPHkSZcuWxbZt27Bt2zaULVsWJ0+eVDtpISIiIv2l9TkuOTk5GDJkCCZMmIB169ZpOxwiIiKdZQhPQNN6xcXExARbtmzRdhhERES6zwBeD631xAUAgoODC7xFkoiIiOh1Wh8qAoDKlSsjKioKR48eRd26dWFhYaG0//UXKxIREVFB2nzJYkmRxKoiDw+PN+6TyWS4ffu2Wv1xVRERFSeuKiJ1ldSqotsPsjTaX0UH9ZYqlwRJVFz+/XZovmSRiIioaAzhr05JzHEBgBUrVqB69eowMzODmZkZqlevjuXL+aIuIiIiVRnA3FxpVFwmTpyImTNnYtiwYfDz8wMAxMTEYOTIkUhISEBUVJSWIyQiIiIpkMQcFwcHB8ydOxc9evRQav/xxx8xbNgwPHz4UK3+OMeFiIoT57iQukpqjsudVM3OcXG35xyXQuXk5KBevXoF2uvWrYuXL5mFEBERqcIQVhVJYo5Lnz59sGjRogLtS5cuRa9evbQQEREREUmRJCouwKvJuXv27EGjRo0AACdOnEBCQgL69u2L8PBwxXEzZ87UVohERESSZgiriiSRuFy6dAl16tQBANy6dQsAULZsWZQtWxaXLl1SHMcl0kRERG9mCH9LSiJx+fPPP7UdAhEREekASSQuRERE9P4MYWBCEpNziYiIiFTBigsREZHe0P+SCxMXIiIiPcGhIiIiIiIJYcWFiIhITxhAwYWJCxERkb7gUBERERGRhLDiQkREpCf4kkUiIiIiCWHFhYiISF/of8GFiQsREZG+MIC8hUNFREREpDtYcSEiItIThrAcmokLERGRnuCqIiIiIiIJYcWFiIhIX+h/wYWJCxERkb4wgLyFQ0VERESkO1hxISIi0hOGsKqIFRciIiLSGay4EBER6QlDWA7NxIWIiEhPcKiIiIiISEKYuBAREZHO4FARERGRnuBQEREREZGEsOJCRESkJwxhVRErLkRERKQzWHEhIiLSE4Ywx4WJCxERkZ4wgLyFQ0VERESkO1hxISIi0hcGUHJh4kJERKQnuKqIiIiISEJYcSEiItITXFVEREREOsMA8hYOFREREZHuYOJCRESkL2Qa3opgwYIFcHd3h5mZGRo2bIiTJ0++xw0VxMSFiIiINOKnn35CeHg4Jk2ahDNnzqBmzZoICgpCSkqKxq7BxIWIiEhPyDT8P3XNnDkTgwYNQv/+/eHj44PFixejdOnS+OGHHzR2j0xciIiI9IRMptlNHS9evMDp06cRGBioaDMyMkJgYCBiYmI0do9cVURERESFys7ORnZ2tlKbXC6HXC4vcOzDhw+Rm5sLR0dHpXZHR0dcu3ZNYzHpZeJippd39f6ys7MRHR2NcePGFfqhI/o3fl7e7PnZ+doOQXL4eZEGTf/9FzElGpGRkUptkyZNQkREhGYvpAaZEEJo7epUojIyMmBtbY309HRYWVlpOxySOH5eSB38vOgndSouL168QOnSpfHzzz8jODhY0R4aGoq0tDRs375dIzFxjgsREREVSi6Xw8rKSml7U0XN1NQUdevWxf79+xVteXl52L9/P/z8/DQWEwdViIiISCPCw8MRGhqKevXqoUGDBpg9ezaePn2K/v37a+waTFyIiIhII7p164YHDx5g4sSJSEpKQq1atbBr164CE3bfBxMXAyKXyzFp0iROnCOV8PNC6uDnhfINHToUQ4cOLbb+OTmXiIiIdAYn5xIREZHOYOJCREREOoOJixY0a9YMX375pbbDIHqriIgI1KpVS9thEBEp4RwXLXj06BFMTExQpkwZbYdC9EaZmZnIzs6Gvb29tkMhIlJg4mIgXrx4AVNTU61dPycnByYmJlq7PhG9H21+h2j7+4ukhUNFWvDvoSJ3d3dMmTIFffv2haWlJdzc3PDrr7/iwYMH6NixIywtLeHr64vY2FjF+atWrYKNjQ22bduGypUrw8zMDEFBQbh3757imPwy//Lly+Hh4QEzMzMAQEJCgqJfKysrdO3aFcnJyQXOW7JkCSpUqIDSpUuja9euSE9PV7qH5cuXw9vbG2ZmZqhatSoWLlyo2Hfnzh3IZDL89NNPCAgIgJmZGdavX18cv0p6i2bNmmH48OH46quvYGdnBycnJ6X3i6j6Wch38OBBNGjQABYWFrCxsYG/vz/u3r2r2L99+3bUqVMHZmZmqFixIiIjI/Hy5cuSuFUqgmbNmimWrVpbW6Ns2bKYMGEC8v8t6+7ujsmTJ6Nv376wsrLC4MGDAQBbtmxBtWrVIJfL4e7ujhkzZij1m39ejx49YGFhgQ8++AALFixQOiYtLQ0DBw6Eg4MDrKys0KJFC5w/f16x/03fX0QAAEElLiAgQIwYMUIIIYSbm5uws7MTixcvFtevXxeff/65sLKyEm3atBGbNm0ScXFxIjg4WHh7e4u8vDwhhBArV64UJiYmol69euLYsWMiNjZWNGjQQDRu3FhxjUmTJgkLCwvRpk0bcebMGXH+/HmRm5sratWqJZo0aSJiY2PF8ePHRd26dUVAQECB81q0aCHOnj0rDh06JDw9PUXPnj0Vx6xbt044OzuLLVu2iNu3b4stW7YIOzs7sWrVKiGEEPHx8QKAcHd3Vxxz//794v/FkpKAgABhZWUlIiIixPXr18Xq1auFTCYTe/bsUfmzULNmTSGEEDk5OcLa2lqMHj1a3Lx5U1y5ckWsWrVK3L17VwghxOHDh4WVlZVYtWqVuHXrltizZ49wd3cXERERWrhzUkVAQICwtLQUI0aMENeuXRPr1q0TpUuXFkuXLhVCvPpusrKyEtOnTxc3b94UN2/eFLGxscLIyEhERUWJuLg4sXLlSmFubi5Wrlyp6NfNzU2UKVNGREdHi7i4ODF37lxhbGws9uzZozgmMDBQfPzxx+LUqVPi+vXrYtSoUcLe3l6kpqYKIQr//iLKx8RFC15PXHr37q3Yl5iYKACICRMmKNpiYmIEAJGYmCiEeJW4ABDHjx9XHHP16lUBQJw4cUII8eo/fBMTE5GSkqI4Zs+ePcLY2FgkJCQo2i5fviwAiJMnTyrOMzY2Fn///bfimD/++EMYGRkprl+pUiWxYcMGpXuaPHmy8PPzE0L8f+Iye/bsov+S6L0FBASIJk2aKLXVr19fjB07VuXPQn7ikpqaKgCIgwcPFnqtli1bim+//Vapbe3atcLZ2VmDd0SaFBAQoPQPIiGEGDt2rPD29hZCvPpuCg4OVjqnZ8+eolWrVkptY8aMET4+Poqf3dzcRJs2bZSO6datm2jbtq0QQoi//vpLWFlZiaysLKVjKlWqJJYsWSKEKPz7iygfh4okwNfXV/Hn/Mci16hRo0BbSkqKoq1UqVKoX7++4ueqVavCxsYGV69eVbS5ubnBwcFB8fPVq1dRoUIFVKhQQdHm4+NT4DxXV1d88MEHip/9/PyQl5eHuLg4PH36FLdu3cKAAQNgaWmp2KZMmYJbt24p3Ve9evXU/2WQRv37swUAzs7OSElJUfmzkM/Ozg79+vVDUFAQPv74Y8yZMweJiYmK/efPn0dUVJTSZ2LQoEFITEzEs2fPiu8G6b00atQIMplM8bOfnx9u3LiB3NxcAAX/G7569Sr8/f2V2vz9/ZXOye/n3/z8/BSfq/PnzyMzMxP29vZKn5f4+Hil75DXv7+I8vGR/xLw70mr+V8ihbXl5eWp1a+FhYUGolOWmZkJAFi2bBkaNmyotM/Y2LjYr0/qeX1CtEwmU/tzlG/lypUYPnw4du3ahZ9++gnjx4/H3r170ahRI2RmZiIyMhKdO3cucB7nJ+iu4voOcXZ2xsGDBwvss7GxKdZrk35g4qKjXr58idjYWDRo0AAAEBcXh7S0NHh7e7/xHG9vb9y7dw/37t1T/Ev7ypUrSEtLg4+Pj+K4hIQE3L9/Hy4uLgCA48ePw8jICF5eXnB0dISLiwtu376NXr16FeMdUnFS9bPwutq1a6N27doYN24c/Pz8sGHDBjRq1Ah16tRBXFwcPD09S+oWSANOnDih9PPx48dRuXLlAv8Iyeft7Y2jR48qtR09ehRVqlRROuf48eMF+s3/bqpTpw6SkpJQqlQpuLu7a+AuyNAwcdFRJiYmGDZsGObOnYtSpUph6NChaNSokSKRKUxgYCBq1KiBXr16Yfbs2Xj58iW++OILBAQEKJWEzczMEBoaiunTpyMjIwPDhw9H165d4eTkBACIjIzE8OHDYW1tjTZt2iA7OxuxsbF4/PgxwsPDi/3e6f2p+lnIFx8fj6VLl6JDhw5wcXFBXFwcbty4gb59+wIAJk6ciPbt28PV1RVdunSBkZERzp8/j0uXLmHKlCklfXukooSEBISHh2PIkCE4c+YM5s2bV2CV0L+NGjUK9evXx+TJk9GtWzfExMRg/vz5SqsKgVfJzLRp0xAcHIy9e/di8+bN+O233wC8+uz5+fkhODgY06ZNQ5UqVXD//n389ttv6NSpE4eY6Z04x0VHlS5dGmPHjkXPnj3h7+8PS0tL/PTTT289RyaTYfv27bC1tUXTpk0RGBiIihUrFjjP09MTnTt3Rrt27dC6dWv4+voqfTENHDgQy5cvx8qVK1GjRg0EBARg1apV8PDwKJZ7Jc1T9bOQr3Tp0rh27RpCQkJQpUoVDB48GGFhYRgyZAgAICgoCDt37sSePXtQv359NGrUCLNmzYKbm1tJ3hapqW/fvnj+/DkaNGiAsLAwjBgxQrHsuTB16tTBpk2bsHHjRlSvXh0TJ05EVFQU+vXrp3TcqFGjEBsbi9q1a2PKlCmYOXMmgoKCALz67P3+++9o2rQp+vfvjypVqqB79+64e/euYj4f0dvwAXQ6aNWqVfjyyy+Rlpam8b4jIiKwbds2nDt3TuN9E5F0NGvWDLVq1cLs2bM12q+7uzu+/PJLvtaEig0rLkRERKQzmLgQERGRzuBQEREREekMVlyIiIhIZzBxISIiIp3BxIWIiIh0BhMXIiIi0hlMXIiIiEhnMHEh0kH9+vVDcHCw4udmzZpp5YFfBw8ehEwmK5aHIeZ7/V6LoiTiJKKSwcSFSEP69esHmUwGmUwGU1NTeHp6IioqCi9fviz2a//yyy+YPHmySseW9F/i7u7uGn86KxEZLr5kkUiD2rRpg5UrVyI7Oxu///47wsLCYGJignHjxhU49sWLFzA1NdXIde3s7DTSDxGR1LHiQqRBcrkcTk5OcHNzw+eff47AwED8+uuvAP5/yGPq1KlwcXGBl5cXAODevXvo2rUrbGxsYGdnh44dO+LOnTuKPnNzcxEeHg4bGxvY29vjq6++wuvPjXx9qCg7Oxtjx45FhQoVIJfL4enpiRUrVuDOnTto3rw5AMDW1hYymUzxgry8vDxER0fDw8MD5ubmqFmzJn7++Wel6/z++++oUqUKzM3N0bx5c6U4iyI3NxcDBgxQXNPLywtz5swp9NjIyEg4ODjAysoKn332GV68eKHYp0rsRKQfWHEhKkbm5uZITU1V/Lx//35YWVlh7969AICcnBwEBQXBz88Pf/31F0qVKoUpU6agTZs2uHDhAkxNTTFjxgysWrUKP/zwA7y9vTFjxgxs3boVLVq0eON1+/bti5iYGMydOxc1a9ZEfHw8Hj58iAoVKmDLli0ICQlBXFwcrKysYG5uDgCIjo7GunXrsHjxYlSuXBmHDx9G79694eDggICAANy7dw+dO3dGWFgYBg8ejNjYWIwaNeq9fj95eXkoX748Nm/eDHt7exw7dgyDBw+Gs7MzunbtqvR7MzMzw8GDB3Hnzh30798f9vb2mDp1qkqxE5EeEUSkEaGhoaJjx45CCCHy8vLE3r17hVwuF6NHj1bsd3R0FNnZ2Ypz1q5dK7y8vEReXp6iLTs7W5ibm4vdu3cLIYRwdnYW06ZNU+zPyckR5cuXV1xLCCECAgLEiBEjhBBCxMXFCQBi7969hcb5559/CgDi8ePHirasrCxRunRpcezYMaVjBwwYIHr06CGEEGLcuHHCx8dHaf/YsWML9PU6Nzc3MWvWrDfuf11YWJgICQlR/BwaGirs7OzE06dPFW2LFi0SlpaWIjc3V6XYC7tnItJNrLgQadDOnTthaWmJnJwc5OXloWfPnoiIiFDsr1GjhtK8lvPnz+PmzZsoU6aMUj9ZWVm4desW0tPTkZiYiIYNGyr2lSpVCvXq1SswXJTv3LlzMDY2VqvScPPmTTx79gytWrVSan/x4gVq164NALh69apSHADg5+en8jXeZMGCBfjhhx+QkJCA58+f48WLF6hVq5bSMTVr1kTp0qWVrpuZmYl79+4hMzPznbETkf5g4kKkQc2bN8eiRYtgamoKFxcXlCql/J+YhYWF0s+ZmZmoW7cu1q9fX6AvBweHIsWQP/SjjszMTADAb7/9hg8++EBpn1wuL1Icqti4cSNGjx6NGTNmwM/PD2XKlMH333+PEydOqNyHtmInIu1g4kKkQRYWFvD09FT5+Dp16uCnn35CuXLlYGVlVegxzs7OOHHiBJo2bQoAePnyJU6fPo06deoUenyNGjWQl5eHQ4cOITAwsMD+/IpPbm6uos3HxwdyuRwJCQlvrNR4e3srJhrnO378+Ltv8i2OHj2Kxo0b44svvlC03bp1q8Bx58+fx/PnzxVJ2fHjx2FpaYkKFSrAzs7unbETkf7gqiIiLerVqxfKli2Ljh074q+//kJ8fDwOHjyI4cOH4++//wYAjBgxAt999x22bduGa9eu4YsvvnjrM1jc3d0RGhqKTz/9FNu2bVP0uWnTJgCAm5sbZDIZdu7ciQcPHiAzMxNlypTB6NGjMXLkSKxevRq3bt3CmTNnMG/ePKxevRoA8Nlnn+HGjRsYM2YM4uLisGHDBqxatUql+/znn39w7tw5pe3x48eoXLkyYmNjsXv3bly/fh0TJkzAqVOnCpz/4sULDBgwAFeuXMHvv/+OSZMmYejQoTAyMlIpdiLSI9qeZEOkL/49OVed/YmJiaJv376ibNmyQi6Xi4oVK4pBgwaJ9PR0IcSrybgjRowQVlZWwsbGRoSHh4u+ffu+cXKuEEI8f/5cjBw5Ujg7OwtTU1Ph6ekpfvjhB8X+qKgo4eTkJGQymQgNDRVCvJpQPHv2bOHl5SVMTEyEg4ODCAoKEocOHVKct2PHDuHp6Snkcrn48MMPxQ8//KDS5FwABba1a9eKrKws0a9fP2FtbS1sbGzE559/Lv7zn/+ImjVrFvi9TZw4Udjb2wtLS0sxaNAgkZWVpTjmXbFzci6R/pAJ8YYZfkREREQSw6EiIiIi0hlMXIiIiEhnMHEhIiIincHEhYiIiHQGExciIiLSGUxciIiISGcwcSEiIiKdwcSFiIiIdAYTFyIiItIZTFyIiIhIZzBxISIiIp3BxIWIiIh0xv8BUeAYzAnPvlEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}