{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyomee2/scooter-parking-detector/blob/main/models/mobilenetv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKqGk6QIxiDv"
      },
      "source": [
        "## êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGz6wFzHaMmM",
        "outputId": "ff0d9139-f32f-4e72-c8e2-fba5e1bbcb2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. tensorflow ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "c4raI73gO6DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMZ5pTbwcGr_",
        "outputId": "cf454d0d-6440-4438-c1e6-8bf15ef529af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from math import floor\n",
        "\n",
        "# ìˆ˜ì •ëœ ê²½ë¡œ: ëª¨ë‘ Google Drive ë‚´ì—ì„œ ì‘ì—…\n",
        "original_base = '/content/gdrive/MyDrive/dataset/cnn'\n",
        "combined_temp = '/content/gdrive/MyDrive/dataset/cnn_2stages/_temp_combined'\n",
        "new_base = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "class_names = ['improper', 'proper', 'noise']\n",
        "random.seed(42)\n",
        "\n",
        "# cnn ë°ì´í„°ì…‹ í†µí•© í›„ ì¬ë¶„í•  ì¤€ë¹„\n",
        "# combined_temp í´ë” ì´ˆê¸°í™” ë° ìƒì„±\n",
        "if os.path.exists(combined_temp):\n",
        "    shutil.rmtree(combined_temp)\n",
        "os.makedirs(combined_temp, exist_ok=True)\n",
        "\n",
        "for cls in class_names:\n",
        "    os.makedirs(os.path.join(combined_temp, cls), exist_ok=True)\n",
        "    for split in splits:\n",
        "        src = os.path.join(original_base, split, cls)\n",
        "        if os.path.exists(src):\n",
        "            for f in os.listdir(src):\n",
        "                src_path = os.path.join(src, f)\n",
        "                if os.path.isfile(src_path):\n",
        "                    # ì›ë³¸ split ì •ë³´ë¥¼ íŒŒì¼ëª…ì— ë¶™ì—¬ì„œ ì €ì¥ (ex: train_abc.jpg)\n",
        "                    shutil.copy(src_path, os.path.join(combined_temp, cls, f\"{split}_{f}\"))\n",
        "\n",
        "print(\"âœ… CNN ë°ì´í„°ì…‹ í†µí•© ì™„ë£Œ!\")\n",
        "\n",
        "# ì¬ë¶„í•  ë° stageë³„ í´ë” ìƒì„± í•¨ìˆ˜\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def split_and_copy(src_dir, dst_map, ratios):\n",
        "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
        "    random.shuffle(files)\n",
        "    total = len(files)\n",
        "    train_end = floor(ratios[0] * total)\n",
        "    val_end = train_end + floor(ratios[1] * total)\n",
        "\n",
        "    for i, phase in enumerate(['train', 'val', 'test']):\n",
        "        phase_files = files[:train_end] if phase == 'train' else \\\n",
        "                      files[train_end:val_end] if phase == 'val' else \\\n",
        "                      files[val_end:]\n",
        "        dst_dir = dst_map[phase]\n",
        "        ensure_dir(dst_dir)\n",
        "        for fname in phase_files:\n",
        "            shutil.copy(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
        "\n",
        "# stage1 / stage2 í´ë˜ìŠ¤ ë§¤í•‘\n",
        "stage1_map = {\n",
        "    'noise': '0_no_kickboard',\n",
        "    'improper': '1_has_kickboard',\n",
        "    'proper': '1_has_kickboard'\n",
        "}\n",
        "\n",
        "stage2_map = {\n",
        "    'improper': '0_improper',\n",
        "    'proper': '2_proper'\n",
        "}\n",
        "\n",
        "# stageë³„ ë¶„í•  ë° ì €ì¥\n",
        "for cls in class_names:\n",
        "    src_dir = os.path.join(combined_temp, cls)\n",
        "\n",
        "    # Stage 1 (noise í¬í•¨)\n",
        "    dst_stage1 = {\n",
        "        'train': os.path.join(new_base, 'stage1', 'train', stage1_map[cls]),\n",
        "        'val': os.path.join(new_base, 'stage1', 'val', stage1_map[cls]),\n",
        "        'test': os.path.join(new_base, 'stage1', 'test', stage1_map[cls])\n",
        "    }\n",
        "    split_and_copy(src_dir, dst_stage1, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "    # Stage 2 (noise ì œì™¸)\n",
        "    if cls != 'noise':\n",
        "        dst_stage2 = {\n",
        "            'train': os.path.join(new_base, 'stage2', 'train', stage2_map[cls]),\n",
        "            'val': os.path.join(new_base, 'stage2', 'val', stage2_map[cls]),\n",
        "            'test': os.path.join(new_base, 'stage2', 'test', stage2_map[cls])\n",
        "        }\n",
        "        split_and_copy(src_dir, dst_stage2, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "print(\"âœ… stage1, stage2 ë°ì´í„°ì…‹ ë¶„í•  ë° ìƒì„± ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "oM4fES1-SKD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78de639d-d4ed-4da0-b719-f01d22f86f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Mobilenet ë°ì´í„°ì…‹ í†µí•© ì™„ë£Œ!\n",
            "âœ… stage1, stage2 ë°ì´í„°ì…‹ ë¶„í•  ë° ìƒì„± ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ì´ìƒ ì´ë¯¸ì§€ ì œê±°"
      ],
      "metadata": {
        "id": "XnjY_hTbhtSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_dataset(directory):\n",
        "    valid_exts = ['.jpg', '.jpeg', '.png']\n",
        "    removed_files = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext not in valid_exts:\n",
        "                file_path = os.path.join(root, fname)\n",
        "                removed_files.append(file_path)\n",
        "                os.remove(file_path)\n",
        "\n",
        "    return removed_files\n",
        "\n",
        "# ë°ì´í„°ì…‹ ê²½ë¡œ ì •ë¦¬\n",
        "removed = clean_dataset('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"âœ… ì‚­ì œëœ ë¹„ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(removed)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b3923d-be82-4da6-d471-994f00b90da8",
        "id": "gD04r0o2Sa7S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì‚­ì œëœ ë¹„ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def clean_corrupted_images(directory):\n",
        "    corrupted = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext in ['.jpg', '.jpeg', '.png']:\n",
        "                fpath = os.path.join(root, fname)\n",
        "                try:\n",
        "                    img = Image.open(fpath)\n",
        "                    img.verify()  # íŒŒì¼ì´ ì§„ì§œ ì´ë¯¸ì§€ì¸ì§€ ê²€ì‚¬\n",
        "                except Exception:\n",
        "                    corrupted.append(fpath)\n",
        "                    os.remove(fpath)\n",
        "    return corrupted\n",
        "\n",
        "# ì‹¤ì œ ì´ë¯¸ì§€ ì—´ì–´ì„œ ê²€ì‚¬\n",
        "bad_files = clean_corrupted_images('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"ğŸ§¹ ì‚­ì œëœ ì†ìƒëœ ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(bad_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQBdAjRd32Oj",
        "outputId": "8bb2b01b-1117-4aa5-8889-4cf9bb4b69f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ ì‚­ì œëœ ì†ìƒëœ ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ëª¨ë¸ í•™ìŠµ"
      ],
      "metadata": {
        "id": "CUSRrcmWh-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "5Hvz3N85uTQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage1_train = os.path.join(base_path, 'stage1', 'train')\n",
        "stage1_val = os.path.join(base_path, 'stage1', 'val')\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# âœ… ë°ì´í„° ì¦ê°• ì„¤ì •\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# âœ… Stage 1: í‚¥ë³´ë“œ ìœ ë¬´ ì´ì§„ ë¶„ë¥˜\n",
        "train_gen_1 = datagen.flow_from_directory(stage1_train, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "val_gen_1 = val_datagen.flow_from_directory(stage1_val, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "\n",
        "base_model_1 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x1 = GlobalAveragePooling2D()(base_model_1.output)\n",
        "out1 = Dense(1, activation='sigmoid')(x1)\n",
        "model_1 = Model(inputs=base_model_1.input, outputs=out1)\n",
        "\n",
        "for layer in base_model_1.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_1.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
        "\n",
        "callbacks_1 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint('/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5',\n",
        "                    monitor='val_auc', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "print(\"\\nğŸ”¹ Stage 1 í•™ìŠµ ì‹œì‘\")\n",
        "history_1 = model_1.fit(train_gen_1, validation_data=val_gen_1, epochs=50, callbacks=callbacks_1)\n",
        "\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# âœ… ë°ì´í„° ì¦ê°• ì„¤ì •\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# âœ… ë°ì´í„° ë¡œë”©\n",
        "train_gen_2 = train_datagen.flow_from_directory(\n",
        "    stage2_train,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # one-hot ì¸ì½”ë”©\n",
        "    shuffle=True\n",
        ")\n",
        "val_gen_2 = val_datagen.flow_from_directory(\n",
        "    stage2_val,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •\n",
        "class_weight_2 = {\n",
        "    0: 10.0,  # improper\n",
        "    1: 1.0    # proper\n",
        "}\n",
        "\n",
        "# âœ… ëª¨ë¸ êµ¬ì„±\n",
        "base_model_2 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x = GlobalAveragePooling2D()(base_model_2.output)\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "model_2 = Model(inputs=base_model_2.input, outputs=out)\n",
        "\n",
        "# âœ… ë§ˆì§€ë§‰ 60ê°œ ë ˆì´ì–´ë§Œ fine-tuning\n",
        "for layer in base_model_2.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_2.layers[-60:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# âœ… ì»´íŒŒì¼\n",
        "model_2.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# âœ… ì½œë°± ì„¤ì •\n",
        "callbacks_2 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint(\n",
        "        '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5',\n",
        "        monitor='val_auc', save_best_only=True, mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "# âœ… í•™ìŠµ\n",
        "print(\"\\nğŸ”¹ Stage 2 í•™ìŠµ ì‹œì‘\")\n",
        "history_2 = model_2.fit(train_gen_2,\n",
        "    validation_data=val_gen_2,\n",
        "    epochs=50,\n",
        "    class_weight=class_weight_2,\n",
        "    callbacks=callbacks_2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp3LAXsvpnWo",
        "outputId": "44be8d2b-ab0e-4be4-ddfc-92096eaabb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 871 images belonging to 2 classes.\n",
            "Found 108 images belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "ğŸ”¹ Stage 1 í•™ìŠµ ì‹œì‘\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - auc: 0.5793 - loss: 0.6663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 11s/step - auc: 0.5819 - loss: 0.6651 - val_auc: 0.7907 - val_loss: 0.5402 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738ms/step - auc: 0.9122 - loss: 0.4867"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 825ms/step - auc: 0.9121 - loss: 0.4859 - val_auc: 0.8935 - val_loss: 0.5458 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - auc: 0.9551 - loss: 0.3637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 812ms/step - auc: 0.9552 - loss: 0.3626 - val_auc: 0.9362 - val_loss: 0.6343 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - auc: 0.9796 - loss: 0.2648"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 774ms/step - auc: 0.9796 - loss: 0.2641 - val_auc: 0.9659 - val_loss: 0.7247 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706ms/step - auc: 0.9864 - loss: 0.2011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 795ms/step - auc: 0.9866 - loss: 0.2007 - val_auc: 0.9785 - val_loss: 0.8026 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - auc: 0.9901 - loss: 0.1699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 758ms/step - auc: 0.9902 - loss: 0.1697 - val_auc: 0.9849 - val_loss: 0.8235 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760ms/step - auc: 0.9963 - loss: 0.1382"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 846ms/step - auc: 0.9962 - loss: 0.1381 - val_auc: 0.9864 - val_loss: 0.7919 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - auc: 0.9986 - loss: 0.1140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 829ms/step - auc: 0.9985 - loss: 0.1140 - val_auc: 0.9878 - val_loss: 0.7936 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - auc: 0.9972 - loss: 0.1097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 834ms/step - auc: 0.9972 - loss: 0.1095 - val_auc: 0.9900 - val_loss: 0.7575 - learning_rate: 1.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693ms/step - auc: 0.9984 - loss: 0.0973"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 789ms/step - auc: 0.9984 - loss: 0.0973 - val_auc: 0.9925 - val_loss: 0.7440 - learning_rate: 1.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736ms/step - auc: 0.9977 - loss: 0.0868"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 832ms/step - auc: 0.9978 - loss: 0.0867 - val_auc: 0.9943 - val_loss: 0.7092 - learning_rate: 1.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 788ms/step - auc: 0.9991 - loss: 0.0757 - val_auc: 0.9943 - val_loss: 0.7042 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722ms/step - auc: 0.9995 - loss: 0.0655 - val_auc: 0.9939 - val_loss: 0.6913 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - auc: 0.9994 - loss: 0.0684"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 808ms/step - auc: 0.9994 - loss: 0.0682 - val_auc: 0.9961 - val_loss: 0.6697 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709ms/step - auc: 0.9998 - loss: 0.0511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 843ms/step - auc: 0.9998 - loss: 0.0512 - val_auc: 0.9975 - val_loss: 0.6648 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 784ms/step - auc: 0.9999 - loss: 0.0480 - val_auc: 0.9975 - val_loss: 0.6309 - learning_rate: 1.0000e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707ms/step - auc: 0.9996 - loss: 0.0477"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 802ms/step - auc: 0.9996 - loss: 0.0478 - val_auc: 0.9986 - val_loss: 0.6049 - learning_rate: 1.0000e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 799ms/step - auc: 0.9998 - loss: 0.0433 - val_auc: 0.9986 - val_loss: 0.5600 - learning_rate: 1.0000e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 754ms/step - auc: 1.0000 - loss: 0.0377 - val_auc: 0.9986 - val_loss: 0.5479 - learning_rate: 1.0000e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 753ms/step - auc: 1.0000 - loss: 0.0352 - val_auc: 0.9986 - val_loss: 0.5268 - learning_rate: 1.0000e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675ms/step - auc: 1.0000 - loss: 0.0339"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 795ms/step - auc: 1.0000 - loss: 0.0338 - val_auc: 0.9989 - val_loss: 0.4842 - learning_rate: 5.0000e-06\n",
            "Epoch 22/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 744ms/step - auc: 1.0000 - loss: 0.0315 - val_auc: 0.9989 - val_loss: 0.4571 - learning_rate: 5.0000e-06\n",
            "Epoch 23/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 779ms/step - auc: 0.9999 - loss: 0.0324 - val_auc: 0.9989 - val_loss: 0.4292 - learning_rate: 5.0000e-06\n",
            "Epoch 24/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680ms/step - auc: 1.0000 - loss: 0.0326"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 774ms/step - auc: 1.0000 - loss: 0.0325 - val_auc: 0.9996 - val_loss: 0.4032 - learning_rate: 5.0000e-06\n",
            "Epoch 25/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 767ms/step - auc: 1.0000 - loss: 0.0278 - val_auc: 0.9996 - val_loss: 0.3791 - learning_rate: 5.0000e-06\n",
            "Epoch 26/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 722ms/step - auc: 1.0000 - loss: 0.0250 - val_auc: 0.9996 - val_loss: 0.3631 - learning_rate: 5.0000e-06\n",
            "Epoch 27/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 768ms/step - auc: 1.0000 - loss: 0.0267 - val_auc: 0.9993 - val_loss: 0.3494 - learning_rate: 5.0000e-06\n",
            "Epoch 28/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 779ms/step - auc: 1.0000 - loss: 0.0289 - val_auc: 0.9996 - val_loss: 0.3287 - learning_rate: 2.5000e-06\n",
            "Epoch 29/50\n",
            "\u001b[1m28/28\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 727ms/step - auc: 1.0000 - loss: 0.0259 - val_auc: 0.9996 - val_loss: 0.3083 - learning_rate: 2.5000e-06\n",
            "Found 751 images belonging to 2 classes.\n",
            "Found 93 images belonging to 2 classes.\n",
            "\n",
            "ğŸ”¹ Stage 2 í•™ìŠµ ì‹œì‘\n",
            "Epoch 1/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - auc: 0.3780 - loss: 2.1322"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 11s/step - auc: 0.3798 - loss: 2.1315 - val_auc: 0.4634 - val_loss: 0.9245 - learning_rate: 1.0000e-05\n",
            "Epoch 2/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642ms/step - auc: 0.5292 - loss: 1.6559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 730ms/step - auc: 0.5286 - loss: 1.6531 - val_auc: 0.6472 - val_loss: 0.6867 - learning_rate: 1.0000e-05\n",
            "Epoch 3/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666ms/step - auc: 0.5625 - loss: 1.3696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 749ms/step - auc: 0.5625 - loss: 1.3691 - val_auc: 0.7881 - val_loss: 0.5517 - learning_rate: 1.0000e-05\n",
            "Epoch 4/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704ms/step - auc: 0.5916 - loss: 1.2526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 791ms/step - auc: 0.5923 - loss: 1.2498 - val_auc: 0.8784 - val_loss: 0.4572 - learning_rate: 1.0000e-05\n",
            "Epoch 5/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669ms/step - auc: 0.6230 - loss: 1.1278"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 754ms/step - auc: 0.6245 - loss: 1.1260 - val_auc: 0.9285 - val_loss: 0.3896 - learning_rate: 1.0000e-05\n",
            "Epoch 6/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799ms/step - auc: 0.7374 - loss: 0.9658"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 895ms/step - auc: 0.7362 - loss: 0.9660 - val_auc: 0.9561 - val_loss: 0.3417 - learning_rate: 1.0000e-05\n",
            "Epoch 7/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682ms/step - auc: 0.7184 - loss: 0.9134"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 764ms/step - auc: 0.7195 - loss: 0.9125 - val_auc: 0.9644 - val_loss: 0.3126 - learning_rate: 1.0000e-05\n",
            "Epoch 8/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - auc: 0.7562 - loss: 0.8678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 784ms/step - auc: 0.7576 - loss: 0.8666 - val_auc: 0.9703 - val_loss: 0.2894 - learning_rate: 1.0000e-05\n",
            "Epoch 9/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648ms/step - auc: 0.8031 - loss: 0.7507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 744ms/step - auc: 0.8039 - loss: 0.7503 - val_auc: 0.9746 - val_loss: 0.2693 - learning_rate: 1.0000e-05\n",
            "Epoch 10/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659ms/step - auc: 0.8614 - loss: 0.6786"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 747ms/step - auc: 0.8612 - loss: 0.6793 - val_auc: 0.9788 - val_loss: 0.2506 - learning_rate: 1.0000e-05\n",
            "Epoch 11/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657ms/step - auc: 0.8463 - loss: 0.6523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 764ms/step - auc: 0.8469 - loss: 0.6532 - val_auc: 0.9790 - val_loss: 0.2381 - learning_rate: 1.0000e-05\n",
            "Epoch 12/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650ms/step - auc: 0.8778 - loss: 0.6291"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 749ms/step - auc: 0.8782 - loss: 0.6280 - val_auc: 0.9793 - val_loss: 0.2259 - learning_rate: 1.0000e-05\n",
            "Epoch 13/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 830ms/step - auc: 0.8876 - loss: 0.5845 - val_auc: 0.9783 - val_loss: 0.2170 - learning_rate: 1.0000e-05\n",
            "Epoch 14/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 680ms/step - auc: 0.9130 - loss: 0.5247 - val_auc: 0.9783 - val_loss: 0.2118 - learning_rate: 1.0000e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 677ms/step - auc: 0.9318 - loss: 0.4632 - val_auc: 0.9773 - val_loss: 0.2103 - learning_rate: 1.0000e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 695ms/step - auc: 0.9460 - loss: 0.4770 - val_auc: 0.9778 - val_loss: 0.2070 - learning_rate: 5.0000e-06\n",
            "Epoch 17/50\n",
            "\u001b[1m24/24\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 723ms/step - auc: 0.9609 - loss: 0.4618 - val_auc: 0.9792 - val_loss: 0.2026 - learning_rate: 5.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ì„ê³„ê°’ ìµœì í™”"
      ],
      "metadata": {
        "id": "jDqz2Owdi6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "val_dir = '/content/gdrive/MyDrive/dataset/cnn/val'\n",
        "model_stage1_path = '/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5'\n",
        "model_stage2_path = '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5'\n",
        "# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model_1 = load_model(model_stage1_path)\n",
        "model_2 = load_model(model_stage2_path)\n",
        "\n",
        "# âœ… ê²€ì¦ ë°ì´í„° ë¡œë”©\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ê²€ì¦ ë°ì´í„° ì œë„ˆë ˆì´í„°\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´ ì¶œë ¥ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)\n",
        "label_map = val_gen.class_indices\n",
        "inv_map = {v: k for k, v in label_map.items()}\n",
        "print(\"\\nâœ… í´ë˜ìŠ¤ ë§¤í•‘ (ê²€ì¦ ë°ì´í„°ì…‹ì˜ ì‹¤ì œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤):\", inv_map)\n",
        "\n",
        "# --- ì„ê³„ê°’ ìµœì í™”: ê²€ì¦ ë°ì´í„° ì‚¬ìš© ---\n",
        "\n",
        "# âœ… ì „ì²´ ê²€ì¦ ì´ë¯¸ì§€ ë° ë¼ë²¨ ìˆ˜ì§‘\n",
        "print(\"\\nê²€ì¦ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
        "x_val_all, y_val_all = [], []\n",
        "for i in range(len(val_gen)):\n",
        "    x_batch, y_batch = val_gen[i]\n",
        "    x_val_all.extend(x_batch)\n",
        "    y_val_all.extend(y_batch)\n",
        "\n",
        "x_val_all = np.array(x_val_all)\n",
        "y_val_all = np.array(y_val_all)\n",
        "y_val_true = np.argmax(y_val_all, axis=1) # One-hot encoded y_val_allì„ ë‹¨ì¼ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
        "print(f\"ì´ ê²€ì¦ ì´ë¯¸ì§€ ìˆ˜: {len(x_val_all)}\")\n",
        "\n",
        "\n",
        "# âœ… Stage 1 ì˜ˆì¸¡ í™•ë¥  (ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´)\n",
        "print(\"\\nStage 1 ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘ (ê²€ì¦ ë°ì´í„°)...\")\n",
        "\n",
        "stage1_val_preds = model_1.predict(x_val_all, verbose=1)\n",
        "\n",
        "\n",
        "# âœ… ì„ê³„ê°’ ìµœì í™” (proper recall â‰¥ 0.85 ì¡°ê±´í•˜ì— improper recall ìµœëŒ€í™”)\n",
        "best_threshold = None\n",
        "best_improper_recall = -1\n",
        "best_val_preds_for_threshold = None # ìµœì  ì„ê³„ê°’ì—ì„œì˜ ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
        "\n",
        "thresholds = np.arange(0.01, 0.5, 0.01) # 0.01ë¶€í„° 0.49ê¹Œì§€ 0.01 ê°„ê²©ìœ¼ë¡œ\n",
        "RECALL_MIN_PROPER = 0.85\n",
        "\n",
        "print(\"\\nğŸ” Threshold íƒìƒ‰ ì‹œì‘ (proper recall â‰¥ 0.85 ì¡°ê±´ í•˜ì—ì„œ improper recall ìµœëŒ€í™” - ê²€ì¦ ë°ì´í„° ì‚¬ìš©)\")\n",
        "\n",
        "for t in thresholds:\n",
        "    # Stage 1 ì˜ˆì¸¡ì„ ì´ì§„í™”: të³´ë‹¤ í¬ë©´ 1_kickboard, ì•„ë‹ˆë©´ 0_no_kickboard\n",
        "    stage1_val_binary = (stage1_val_preds > t).astype(int).flatten()\n",
        "\n",
        "    # Stage 1ì—ì„œ '1' (has_kickboard)ìœ¼ë¡œ ë¶„ë¥˜ëœ ì´ë¯¸ì§€ì˜ ì¸ë±ìŠ¤\n",
        "    stage2_val_indices = np.where(stage1_val_binary == 1)[0]\n",
        "    x_val_stage2 = x_val_all[stage2_val_indices]\n",
        "\n",
        "    # ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ë°°ì—´ ì´ˆê¸°í™”: ê¸°ë³¸ê°’ì€ Stage 1ì—ì„œ 0(no_kickboard)ìœ¼ë¡œ ë¶„ë¥˜ëœ 'noise' (ìµœì¢… í´ë˜ìŠ¤ ì¸ë±ìŠ¤: 1)\n",
        "    final_val_preds = np.full_like(stage1_val_binary, fill_value=1)\n",
        "\n",
        "    # Stage 2ë¡œ ë„˜ì–´ê°ˆ ì´ë¯¸ì§€ê°€ ìˆì„ ê²½ìš° Stage 2 ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    if len(x_val_stage2) > 0:\n",
        "        stage2_val_preds = model_2.predict(x_val_stage2, verbose=0)\n",
        "        # Stage 2ëŠ” 0:improper, 1:proper ì…ë‹ˆë‹¤.\n",
        "        stage2_val_classes = np.argmax(stage2_val_preds, axis=1) # Stage 2ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ (0 ë˜ëŠ” 1)\n",
        "\n",
        "        # Stage 2 ì˜ˆì¸¡ì„ ìµœì¢… 3ê°œ í´ë˜ìŠ¤ (0:improper, 1:noise, 2:proper)ì— ë§¤í•‘\n",
        "        # Stage 2ê°€ 0(improper)ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©´ ìµœì¢… 0(improper)\n",
        "        # Stage 2ê°€ 1(proper)ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©´ ìµœì¢… 2(proper)\n",
        "        final_val_preds[stage2_val_indices] = np.where(stage2_val_classes == 0, 0, 2)\n",
        "    # else ë¸”ë¡ì€ ìœ„ì— final_val_preds ì´ˆê¸°í™”ë¡œ ì´ë¯¸ ì²˜ë¦¬ë¨: Stage 2ë¡œ ë„˜ì–´ê°ˆ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ noise(1)\n",
        "\n",
        "    # ë¶„ë¥˜ ë¦¬í¬íŠ¸ ìƒì„± ë° ì¬í˜„ìœ¨ ì¶”ì¶œ\n",
        "    report = classification_report(y_val_true, final_val_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    # 'proper'ì™€ 'improper' í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì¬í˜„ìœ¨ ì¶”ì¶œ\n",
        "    # inv_map (0: improper, 1: noise, 2: proper)ì— ë”°ë¼\n",
        "    # properëŠ” '2', improperëŠ” '0'\n",
        "    proper_recall = report.get('2', {}).get('recall', 0.0) # proper (í´ë˜ìŠ¤ 2)ì˜ recall\n",
        "    improper_recall = report.get('0', {}).get('recall', 0.0) # improper (í´ë˜ìŠ¤ 0)ì˜ recall\n",
        "\n",
        "    if proper_recall >= RECALL_MIN_PROPER:\n",
        "        print(f\" - threshold {t:.2f}: proper recall = {proper_recall:.4f}, improper recall = {improper_recall:.4f}\")\n",
        "        if improper_recall > best_improper_recall:\n",
        "            best_improper_recall = improper_recall\n",
        "            best_threshold = t\n",
        "            best_val_preds_for_threshold = final_val_preds.copy()\n",
        "\n",
        "# âœ… ìµœì  ì„ê³„ê°’ ê²°ê³¼ ì¶œë ¥ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)\n",
        "print(\"\\n--- ì„ê³„ê°’ ìµœì í™” ê²°ê³¼ ---\")\n",
        "if best_threshold is not None:\n",
        "    print(f\"\\nâœ… ìµœì  threshold (ê²€ì¦ ë°ì´í„° ê¸°ì¤€): {best_threshold:.2f} (improper recall = {best_improper_recall:.4f}, proper recall â‰¥ {RECALL_MIN_PROPER:.2f})\")\n",
        "    print(\"\\nâœ… Classification Report (ìµœì  ì„ê³„ê°’ ì ìš©ëœ ê²€ì¦ ë°ì´í„° ê²°ê³¼)\")\n",
        "    print(classification_report(y_val_true, best_val_preds_for_threshold, target_names=['improper', 'noise', 'proper'], zero_division=0))\n",
        "    print(\"\\nâœ… Confusion Matrix (ìµœì  ì„ê³„ê°’ ì ìš©ëœ ê²€ì¦ ë°ì´í„° ê²°ê³¼)\")\n",
        "    print(confusion_matrix(y_val_true, best_val_preds_for_threshold))\n",
        "\n",
        "    # AUC ê³„ì‚°\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    y_val_true_one_hot = to_categorical(y_val_true, num_classes=3)\n",
        "    best_val_preds_for_threshold_one_hot = to_categorical(best_val_preds_for_threshold, num_classes=3)\n",
        "    auc = roc_auc_score(y_val_true_one_hot, best_val_preds_for_threshold_one_hot, multi_class='ovr')\n",
        "    print(f\"\\nâœ… AUC (ê²€ì¦ ë°ì´í„°, macro): {auc:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ proper recall â‰¥ {RECALL_MIN_PROPER:.2f}ë¥¼ ë§Œì¡±í•˜ëŠ” thresholdê°€ ê²€ì¦ ë°ì´í„°ì—ì„œ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL6aFTbpcrp_",
        "outputId": "c0990c9c-c97d-40bc-96fe-9ae09dbb2566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 109 images belonging to 3 classes.\n",
            "\n",
            "âœ… í´ë˜ìŠ¤ ë§¤í•‘ (ê²€ì¦ ë°ì´í„°ì…‹ì˜ ì‹¤ì œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤): {0: 'improper', 1: 'noise', 2: 'proper'}\n",
            "\n",
            "ê²€ì¦ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\n",
            "ì´ ê²€ì¦ ì´ë¯¸ì§€ ìˆ˜: 109\n",
            "\n",
            "Stage 1 ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘ (ê²€ì¦ ë°ì´í„°)...\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 991ms/step\n",
            "\n",
            "ğŸ” Threshold íƒìƒ‰ ì‹œì‘ (proper recall â‰¥ 0.85 ì¡°ê±´ í•˜ì—ì„œ improper recall ìµœëŒ€í™” - ê²€ì¦ ë°ì´í„° ì‚¬ìš©)\n",
            " - threshold 0.01: proper recall = 1.0000, improper recall = 0.7419\n",
            " - threshold 0.02: proper recall = 1.0000, improper recall = 0.7419\n",
            " - threshold 0.03: proper recall = 1.0000, improper recall = 0.7419\n",
            " - threshold 0.04: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.05: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.06: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.07: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.08: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.09: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.10: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.11: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.12: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.13: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.14: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.15: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.16: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.17: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.18: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.19: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.20: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.21: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.22: proper recall = 1.0000, improper recall = 0.7097\n",
            " - threshold 0.23: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.24: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.25: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.26: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.27: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.28: proper recall = 1.0000, improper recall = 0.6774\n",
            " - threshold 0.29: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.30: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.31: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.32: proper recall = 0.9841, improper recall = 0.6774\n",
            " - threshold 0.33: proper recall = 0.9683, improper recall = 0.6774\n",
            " - threshold 0.34: proper recall = 0.9524, improper recall = 0.6774\n",
            " - threshold 0.35: proper recall = 0.9365, improper recall = 0.6774\n",
            " - threshold 0.36: proper recall = 0.9365, improper recall = 0.6774\n",
            " - threshold 0.37: proper recall = 0.9206, improper recall = 0.6774\n",
            " - threshold 0.38: proper recall = 0.9206, improper recall = 0.6774\n",
            " - threshold 0.39: proper recall = 0.9206, improper recall = 0.6774\n",
            " - threshold 0.40: proper recall = 0.9048, improper recall = 0.6774\n",
            " - threshold 0.41: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.42: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.43: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.44: proper recall = 0.9048, improper recall = 0.6452\n",
            " - threshold 0.45: proper recall = 0.8889, improper recall = 0.6452\n",
            " - threshold 0.46: proper recall = 0.8889, improper recall = 0.6452\n",
            " - threshold 0.47: proper recall = 0.8889, improper recall = 0.6129\n",
            " - threshold 0.48: proper recall = 0.8889, improper recall = 0.6129\n",
            " - threshold 0.49: proper recall = 0.8889, improper recall = 0.6129\n",
            "\n",
            "--- ì„ê³„ê°’ ìµœì í™” ê²°ê³¼ ---\n",
            "\n",
            "âœ… ìµœì  threshold (ê²€ì¦ ë°ì´í„° ê¸°ì¤€): 0.01 (improper recall = 0.7419, proper recall â‰¥ 0.85)\n",
            "\n",
            "âœ… Classification Report (ìµœì  ì„ê³„ê°’ ì ìš©ëœ ê²€ì¦ ë°ì´í„° ê²°ê³¼)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    improper       1.00      0.74      0.85        31\n",
            "       noise       1.00      1.00      1.00        15\n",
            "      proper       0.89      1.00      0.94        63\n",
            "\n",
            "    accuracy                           0.93       109\n",
            "   macro avg       0.96      0.91      0.93       109\n",
            "weighted avg       0.93      0.93      0.92       109\n",
            "\n",
            "\n",
            "âœ… Confusion Matrix (ìµœì  ì„ê³„ê°’ ì ìš©ëœ ê²€ì¦ ë°ì´í„° ê²°ê³¼)\n",
            "[[23  0  8]\n",
            " [ 0 15  0]\n",
            " [ 0  0 63]]\n",
            "\n",
            "âœ… AUC (ê²€ì¦ ë°ì´í„°, macro): 0.9280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ì‹œê°í™”"
      ],
      "metadata": {
        "id": "NZwHKx1BkIGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ ì´ë¦„\n",
        "class_names = ['improper', 'noise', 'proper']\n",
        "\n",
        "# âœ… í˜¼ë™í–‰ë ¬ ì •ì˜ (ì§ì ‘ ì…ë ¥í•œ ê²½ìš°)\n",
        "cm = np.array([[23 ,0,  8],\n",
        " [ 0, 15,  0],\n",
        " [ 0,  0, 63]])\n",
        "\n",
        "# âœ… ì‹œê°í™”\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "WFiBPZMDkKAM",
        "outputId": "c855df47-e1a3-4b9d-cc5f-71faaa54c17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}