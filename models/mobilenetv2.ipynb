{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyomee2/scooter-parking-detector/blob/main/models/mobilenetv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKqGk6QIxiDv"
      },
      "source": [
        "## êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGz6wFzHaMmM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. tensorflow ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "c4raI73gO6DH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMZ5pTbwcGr_"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from math import floor\n",
        "\n",
        "# ìˆ˜ì •ëœ ê²½ë¡œ: ëª¨ë‘ Google Drive ë‚´ì—ì„œ ì‘ì—…\n",
        "original_base = '/content/gdrive/MyDrive/dataset/cnn'\n",
        "combined_temp = '/content/gdrive/MyDrive/dataset/cnn_2stages/_temp_combined'\n",
        "new_base = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "class_names = ['improper', 'proper', 'noise']\n",
        "random.seed(42)\n",
        "\n",
        "# cnn ë°ì´í„°ì…‹ í†µí•© í›„ ì¬ë¶„í•  ì¤€ë¹„\n",
        "# combined_temp í´ë” ì´ˆê¸°í™” ë° ìƒì„±\n",
        "if os.path.exists(combined_temp):\n",
        "    shutil.rmtree(combined_temp)\n",
        "os.makedirs(combined_temp, exist_ok=True)\n",
        "\n",
        "for cls in class_names:\n",
        "    os.makedirs(os.path.join(combined_temp, cls), exist_ok=True)\n",
        "    for split in splits:\n",
        "        src = os.path.join(original_base, split, cls)\n",
        "        if os.path.exists(src):\n",
        "            for f in os.listdir(src):\n",
        "                src_path = os.path.join(src, f)\n",
        "                if os.path.isfile(src_path):\n",
        "                    # ì›ë³¸ split ì •ë³´ë¥¼ íŒŒì¼ëª…ì— ë¶™ì—¬ì„œ ì €ì¥ (ex: train_abc.jpg)\n",
        "                    shutil.copy(src_path, os.path.join(combined_temp, cls, f\"{split}_{f}\"))\n",
        "\n",
        "print(\"âœ… CNN ë°ì´í„°ì…‹ í†µí•© ì™„ë£Œ!\")\n",
        "\n",
        "# ì¬ë¶„í•  ë° stageë³„ í´ë” ìƒì„± í•¨ìˆ˜\n",
        "def ensure_dir(path):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "def split_and_copy(src_dir, dst_map, ratios):\n",
        "    files = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
        "    random.shuffle(files)\n",
        "    total = len(files)\n",
        "    train_end = floor(ratios[0] * total)\n",
        "    val_end = train_end + floor(ratios[1] * total)\n",
        "\n",
        "    for i, phase in enumerate(['train', 'val', 'test']):\n",
        "        phase_files = files[:train_end] if phase == 'train' else \\\n",
        "                      files[train_end:val_end] if phase == 'val' else \\\n",
        "                      files[val_end:]\n",
        "        dst_dir = dst_map[phase]\n",
        "        ensure_dir(dst_dir)\n",
        "        for fname in phase_files:\n",
        "            shutil.copy(os.path.join(src_dir, fname), os.path.join(dst_dir, fname))\n",
        "\n",
        "# stage1 / stage2 í´ë˜ìŠ¤ ë§¤í•‘\n",
        "stage1_map = {\n",
        "    'noise': '0_no_kickboard',\n",
        "    'improper': '1_has_kickboard',\n",
        "    'proper': '1_has_kickboard'\n",
        "}\n",
        "\n",
        "stage2_map = {\n",
        "    'improper': '0_improper',\n",
        "    'proper': '2_proper'\n",
        "}\n",
        "\n",
        "# stageë³„ ë¶„í•  ë° ì €ì¥\n",
        "for cls in class_names:\n",
        "    src_dir = os.path.join(combined_temp, cls)\n",
        "\n",
        "    # Stage 1 (noise í¬í•¨)\n",
        "    dst_stage1 = {\n",
        "        'train': os.path.join(new_base, 'stage1', 'train', stage1_map[cls]),\n",
        "        'val': os.path.join(new_base, 'stage1', 'val', stage1_map[cls]),\n",
        "        'test': os.path.join(new_base, 'stage1', 'test', stage1_map[cls])\n",
        "    }\n",
        "    split_and_copy(src_dir, dst_stage1, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "    # Stage 2 (noise ì œì™¸)\n",
        "    if cls != 'noise':\n",
        "        dst_stage2 = {\n",
        "            'train': os.path.join(new_base, 'stage2', 'train', stage2_map[cls]),\n",
        "            'val': os.path.join(new_base, 'stage2', 'val', stage2_map[cls]),\n",
        "            'test': os.path.join(new_base, 'stage2', 'test', stage2_map[cls])\n",
        "        }\n",
        "        split_and_copy(src_dir, dst_stage2, ratios=(0.8, 0.1, 0.1))\n",
        "\n",
        "print(\"âœ… stage1, stage2 ë°ì´í„°ì…‹ ë¶„í•  ë° ìƒì„± ì™„ë£Œ!\")"
      ],
      "metadata": {
        "id": "oM4fES1-SKD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ì´ìƒ ì´ë¯¸ì§€ ì œê±°"
      ],
      "metadata": {
        "id": "XnjY_hTbhtSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_dataset(directory):\n",
        "    valid_exts = ['.jpg', '.jpeg', '.png']\n",
        "    removed_files = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext not in valid_exts:\n",
        "                file_path = os.path.join(root, fname)\n",
        "                removed_files.append(file_path)\n",
        "                os.remove(file_path)\n",
        "\n",
        "    return removed_files\n",
        "\n",
        "# ë°ì´í„°ì…‹ ê²½ë¡œ ì •ë¦¬\n",
        "removed = clean_dataset('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"âœ… ì‚­ì œëœ ë¹„ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(removed)}\")\n"
      ],
      "metadata": {
        "id": "gD04r0o2Sa7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def clean_corrupted_images(directory):\n",
        "    corrupted = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for fname in files:\n",
        "            ext = os.path.splitext(fname)[-1].lower()\n",
        "            if ext in ['.jpg', '.jpeg', '.png']:\n",
        "                fpath = os.path.join(root, fname)\n",
        "                try:\n",
        "                    img = Image.open(fpath)\n",
        "                    img.verify()  # íŒŒì¼ì´ ì§„ì§œ ì´ë¯¸ì§€ì¸ì§€ ê²€ì‚¬\n",
        "                except Exception:\n",
        "                    corrupted.append(fpath)\n",
        "                    os.remove(fpath)\n",
        "    return corrupted\n",
        "\n",
        "# ì‹¤ì œ ì´ë¯¸ì§€ ì—´ì–´ì„œ ê²€ì‚¬\n",
        "bad_files = clean_corrupted_images('/content/gdrive/MyDrive/cnn_2stages')\n",
        "print(f\"ğŸ§¹ ì‚­ì œëœ ì†ìƒëœ ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(bad_files)}\")\n"
      ],
      "metadata": {
        "id": "OQBdAjRd32Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ëª¨ë¸ í•™ìŠµ"
      ],
      "metadata": {
        "id": "CUSRrcmWh-pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage1_train = os.path.join(base_path, 'stage1', 'train')\n",
        "stage1_val = os.path.join(base_path, 'stage1', 'val')\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# âœ… ë°ì´í„° ì¦ê°• ì„¤ì •\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# âœ… Stage 1: í‚¥ë³´ë“œ ìœ ë¬´ ì´ì§„ ë¶„ë¥˜\n",
        "train_gen_1 = datagen.flow_from_directory(stage1_train, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "val_gen_1 = val_datagen.flow_from_directory(stage1_val, target_size=(224, 224), batch_size=32, class_mode='binary')\n",
        "\n",
        "base_model_1 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x1 = GlobalAveragePooling2D()(base_model_1.output)\n",
        "out1 = Dense(1, activation='sigmoid')(x1)\n",
        "model_1 = Model(inputs=base_model_1.input, outputs=out1)\n",
        "\n",
        "for layer in base_model_1.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_1.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
        "\n",
        "callbacks_1 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint('/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5',\n",
        "                    monitor='val_auc', save_best_only=True, mode='max')\n",
        "]\n",
        "\n",
        "print(\"\\nğŸ”¹ Stage 1 í•™ìŠµ ì‹œì‘\")\n",
        "history_1 = model_1.fit(train_gen_1, validation_data=val_gen_1, epochs=50, callbacks=callbacks_1)\n",
        "\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "base_path = '/content/gdrive/MyDrive/dataset/cnn_2stages'\n",
        "stage2_train = os.path.join(base_path, 'stage2', 'train')\n",
        "stage2_val = os.path.join(base_path, 'stage2', 'val')\n",
        "\n",
        "# âœ… ë°ì´í„° ì¦ê°• ì„¤ì •\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# âœ… ë°ì´í„° ë¡œë”©\n",
        "train_gen_2 = train_datagen.flow_from_directory(\n",
        "    stage2_train,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',  # one-hot ì¸ì½”ë”©\n",
        "    shuffle=True\n",
        ")\n",
        "val_gen_2 = val_datagen.flow_from_directory(\n",
        "    stage2_val,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •\n",
        "class_weight_2 = {\n",
        "    0: 10.0,  # improper\n",
        "    1: 1.0    # proper\n",
        "}\n",
        "\n",
        "# âœ… ëª¨ë¸ êµ¬ì„±\n",
        "base_model_2 = MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "x = GlobalAveragePooling2D()(base_model_2.output)\n",
        "out = Dense(2, activation='softmax')(x)\n",
        "model_2 = Model(inputs=base_model_2.input, outputs=out)\n",
        "\n",
        "# âœ… ë§ˆì§€ë§‰ 60ê°œ ë ˆì´ì–´ë§Œ fine-tuning\n",
        "for layer in base_model_2.layers[:-60]:\n",
        "    layer.trainable = False\n",
        "for layer in base_model_2.layers[-60:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# âœ… ì»´íŒŒì¼\n",
        "model_2.compile(\n",
        "    optimizer=Adam(1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[AUC(name='auc')]\n",
        ")\n",
        "\n",
        "# âœ… ì½œë°± ì„¤ì •\n",
        "callbacks_2 = [\n",
        "    EarlyStopping(monitor='val_auc', patience=5, mode='max', restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max'),\n",
        "    ModelCheckpoint(\n",
        "        '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5',\n",
        "        monitor='val_auc', save_best_only=True, mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "# âœ… í•™ìŠµ\n",
        "print(\"\\nğŸ”¹ Stage 2 í•™ìŠµ ì‹œì‘\")\n",
        "history_2 = model_2.fit(train_gen_2,\n",
        "    validation_data=val_gen_2,\n",
        "    epochs=50,\n",
        "    class_weight=class_weight_2,\n",
        "    callbacks=callbacks_2\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "wp3LAXsvpnWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ì„ê³„ê°’ ìµœì í™”"
      ],
      "metadata": {
        "id": "jDqz2Owdi6_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "val_dir = '/content/gdrive/MyDrive/dataset/cnn/val'\n",
        "model_stage1_path = '/content/gdrive/MyDrive/mobilenet/best_stage1_mobilenetv2.h5'\n",
        "model_stage2_path = '/content/gdrive/MyDrive/mobilenet/best_stage2_mobilenetv2_focused_improper.h5'\n",
        "# âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "model_1 = load_model(model_stage1_path)\n",
        "model_2 = load_model(model_stage2_path)\n",
        "\n",
        "# âœ… ê²€ì¦ ë°ì´í„° ë¡œë”©\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# ê²€ì¦ ë°ì´í„° ì œë„ˆë ˆì´í„°\n",
        "val_gen = datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ ë§¤í•‘ ì •ë³´ ì¶œë ¥ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)\n",
        "label_map = val_gen.class_indices\n",
        "inv_map = {v: k for k, v in label_map.items()}\n",
        "print(\"\\nâœ… í´ë˜ìŠ¤ ë§¤í•‘ (ê²€ì¦ ë°ì´í„°ì…‹ì˜ ì‹¤ì œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤):\", inv_map)\n",
        "\n",
        "# --- ì„ê³„ê°’ ìµœì í™”: ê²€ì¦ ë°ì´í„° ì‚¬ìš© ---\n",
        "\n",
        "# âœ… ì „ì²´ ê²€ì¦ ì´ë¯¸ì§€ ë° ë¼ë²¨ ìˆ˜ì§‘\n",
        "print(\"\\nê²€ì¦ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...\")\n",
        "x_val_all, y_val_all = [], []\n",
        "for i in range(len(val_gen)):\n",
        "    x_batch, y_batch = val_gen[i]\n",
        "    x_val_all.extend(x_batch)\n",
        "    y_val_all.extend(y_batch)\n",
        "\n",
        "x_val_all = np.array(x_val_all)\n",
        "y_val_all = np.array(y_val_all)\n",
        "y_val_true = np.argmax(y_val_all, axis=1) # One-hot encoded y_val_allì„ ë‹¨ì¼ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜\n",
        "print(f\"ì´ ê²€ì¦ ì´ë¯¸ì§€ ìˆ˜: {len(x_val_all)}\")\n",
        "\n",
        "\n",
        "# âœ… Stage 1 ì˜ˆì¸¡ í™•ë¥  (ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´)\n",
        "print(\"\\nStage 1 ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘ (ê²€ì¦ ë°ì´í„°)...\")\n",
        "\n",
        "stage1_val_preds = model_1.predict(x_val_all, verbose=1)\n",
        "\n",
        "\n",
        "# âœ… ì„ê³„ê°’ ìµœì í™” (proper recall â‰¥ 0.85 ì¡°ê±´í•˜ì— improper recall ìµœëŒ€í™”)\n",
        "best_threshold = None\n",
        "best_improper_recall = -1\n",
        "best_val_preds_for_threshold = None # ìµœì  ì„ê³„ê°’ì—ì„œì˜ ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
        "\n",
        "thresholds = np.arange(0.01, 0.5, 0.01) # 0.01ë¶€í„° 0.49ê¹Œì§€ 0.01 ê°„ê²©ìœ¼ë¡œ\n",
        "RECALL_MIN_PROPER = 0.85\n",
        "\n",
        "print(\"\\nğŸ” Threshold íƒìƒ‰ ì‹œì‘ (proper recall â‰¥ 0.85 ì¡°ê±´ í•˜ì—ì„œ improper recall ìµœëŒ€í™” - ê²€ì¦ ë°ì´í„° ì‚¬ìš©)\")\n",
        "\n",
        "for t in thresholds:\n",
        "    # Stage 1 ì˜ˆì¸¡ì„ ì´ì§„í™”: të³´ë‹¤ í¬ë©´ 1_kickboard, ì•„ë‹ˆë©´ 0_no_kickboard\n",
        "    stage1_val_binary = (stage1_val_preds > t).astype(int).flatten()\n",
        "\n",
        "    # Stage 1ì—ì„œ '1' (has_kickboard)ìœ¼ë¡œ ë¶„ë¥˜ëœ ì´ë¯¸ì§€ì˜ ì¸ë±ìŠ¤\n",
        "    stage2_val_indices = np.where(stage1_val_binary == 1)[0]\n",
        "    x_val_stage2 = x_val_all[stage2_val_indices]\n",
        "\n",
        "    # ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ë°°ì—´ ì´ˆê¸°í™”: ê¸°ë³¸ê°’ì€ Stage 1ì—ì„œ 0(no_kickboard)ìœ¼ë¡œ ë¶„ë¥˜ëœ 'noise' (ìµœì¢… í´ë˜ìŠ¤ ì¸ë±ìŠ¤: 1)\n",
        "    final_val_preds = np.full_like(stage1_val_binary, fill_value=1)\n",
        "\n",
        "    # Stage 2ë¡œ ë„˜ì–´ê°ˆ ì´ë¯¸ì§€ê°€ ìˆì„ ê²½ìš° Stage 2 ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "    if len(x_val_stage2) > 0:\n",
        "        stage2_val_preds = model_2.predict(x_val_stage2, verbose=0)\n",
        "        # Stage 2ëŠ” 0:improper, 1:proper ì…ë‹ˆë‹¤.\n",
        "        stage2_val_classes = np.argmax(stage2_val_preds, axis=1) # Stage 2ì˜ ì˜ˆì¸¡ í´ë˜ìŠ¤ (0 ë˜ëŠ” 1)\n",
        "\n",
        "        # Stage 2 ì˜ˆì¸¡ì„ ìµœì¢… 3ê°œ í´ë˜ìŠ¤ (0:improper, 1:noise, 2:proper)ì— ë§¤í•‘\n",
        "        # Stage 2ê°€ 0(improper)ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©´ ìµœì¢… 0(improper)\n",
        "        # Stage 2ê°€ 1(proper)ìœ¼ë¡œ ì˜ˆì¸¡í•˜ë©´ ìµœì¢… 2(proper)\n",
        "        final_val_preds[stage2_val_indices] = np.where(stage2_val_classes == 0, 0, 2)\n",
        "    # else ë¸”ë¡ì€ ìœ„ì— final_val_preds ì´ˆê¸°í™”ë¡œ ì´ë¯¸ ì²˜ë¦¬ë¨: Stage 2ë¡œ ë„˜ì–´ê°ˆ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ëª¨ë‘ noise(1)\n",
        "\n",
        "    # ë¶„ë¥˜ ë¦¬í¬íŠ¸ ìƒì„± ë° ì¬í˜„ìœ¨ ì¶”ì¶œ\n",
        "    report = classification_report(y_val_true, final_val_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    # 'proper'ì™€ 'improper' í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ì¬í˜„ìœ¨ ì¶”ì¶œ\n",
        "    # inv_map (0: improper, 1: noise, 2: proper)ì— ë”°ë¼\n",
        "    # properëŠ” '2', improperëŠ” '0'\n",
        "    proper_recall = report.get('2', {}).get('recall', 0.0) # proper (í´ë˜ìŠ¤ 2)ì˜ recall\n",
        "    improper_recall = report.get('0', {}).get('recall', 0.0) # improper (í´ë˜ìŠ¤ 0)ì˜ recall\n",
        "\n",
        "    if proper_recall >= RECALL_MIN_PROPER:\n",
        "        print(f\" - threshold {t:.2f}: proper recall = {proper_recall:.4f}, improper recall = {improper_recall:.4f}\")\n",
        "        if improper_recall > best_improper_recall:\n",
        "            best_improper_recall = improper_recall\n",
        "            best_threshold = t\n",
        "            best_val_preds_for_threshold = final_val_preds.copy()\n",
        "\n",
        "# âœ… ìµœì  ì„ê³„ê°’ ê²°ê³¼ ì¶œë ¥ (ê²€ì¦ ë°ì´í„° ê¸°ì¤€)\n",
        "print(\"\\n--- ì„ê³„ê°’ ìµœì í™” ê²°ê³¼ ---\")\n",
        "if best_threshold is not None:\n",
        "    print(f\"\\nâœ… ìµœì  threshold (ê²€ì¦ ë°ì´í„° ê¸°ì¤€): {best_threshold:.2f} (improper recall = {best_improper_recall:.4f}, proper recall â‰¥ {RECALL_MIN_PROPER:.2f})\")\n",
        "    print(\"\\nâœ… Classification Report (ìµœì  ì„ê³„ê°’ ì ìš©ëœ ê²€ì¦ ë°ì´í„° ê²°ê³¼)\")\n",
        "    print(classification_report(y_val_true, best_val_preds_for_threshold, target_names=['improper', 'noise', 'proper'], zero_division=0))\n",
        "    print(\"\\nâœ… Confusion Matrix (ìµœì  ì„ê³„ê°’ ì ìš©ëœ ê²€ì¦ ë°ì´í„° ê²°ê³¼)\")\n",
        "    print(confusion_matrix(y_val_true, best_val_preds_for_threshold))\n",
        "\n",
        "    # AUC ê³„ì‚°\n",
        "    from tensorflow.keras.utils import to_categorical\n",
        "    y_val_true_one_hot = to_categorical(y_val_true, num_classes=3)\n",
        "    best_val_preds_for_threshold_one_hot = to_categorical(best_val_preds_for_threshold, num_classes=3)\n",
        "    auc = roc_auc_score(y_val_true_one_hot, best_val_preds_for_threshold_one_hot, multi_class='ovr')\n",
        "    print(f\"\\nâœ… AUC (ê²€ì¦ ë°ì´í„°, macro): {auc:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ proper recall â‰¥ {RECALL_MIN_PROPER:.2f}ë¥¼ ë§Œì¡±í•˜ëŠ” thresholdê°€ ê²€ì¦ ë°ì´í„°ì—ì„œ ì—†ìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "id": "nL6aFTbpcrp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. ì‹œê°í™”"
      ],
      "metadata": {
        "id": "NZwHKx1BkIGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ ì´ë¦„\n",
        "class_names = ['improper', 'noise', 'proper']\n",
        "\n",
        "# âœ… í˜¼ë™í–‰ë ¬ ì •ì˜ (ì§ì ‘ ì…ë ¥í•œ ê²½ìš°)\n",
        "cm = np.array([[23 ,0,  8],\n",
        " [ 0, 15,  0],\n",
        " [ 0,  0, 63]])\n",
        "\n",
        "# âœ… ì‹œê°í™”\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WFiBPZMDkKAM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}